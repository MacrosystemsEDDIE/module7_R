---
title: "Macrosystems EDDIE Module 7: Using Data to Improve Ecological Forecasts"
author: "Mary Lofton, Tadhg Moore, Quinn Thomas, Cayelan Carey"
date: "`r Sys.Date()`"
output:
  github_document: default
---

## Purpose of this R Markdown

This R Markdown contains code to reproduce the basic functionality of "Macrosystems EDDIE Module 7: Using Data to Improve Ecological Forecasts" outside of R Shiny. The code can be used by students to better understand what is happening "under the hood" of the Shiny app, which can be found at the following link:  
https://macrosystemseddie.shinyapps.io/module7/. 

Alternatively, students can complete this version of the module instead of the Shiny app version. 

## Summary

Focal question for this module:   
**How can we use data to improve ecological forecasts?**

To be useful for management, ecological forecasts need to be both accurate enough for managers to be able to rely on them for decision-making and include a representation of forecast uncertainty, so managers can properly interpret the probability of future events. To improve forecast accuracy, we can update forecasts with observational data once they become available, a process known as **data assimilation.** Recent improvements in environmental sensor technology and an increase in the number of sensors deployed in ecosystems have resulted in an increase in the availability of data for assimilation to help develop and improve forecasts for natural resource management. In this module, you will develop an autoregressive model of primary productivity and use the model to generate forecasts. You will then explore how assimilating data at different temporal frequencies (e.g., daily, weekly) and with different levels of observation uncertainty affects forecast accuracy. 

## Learning Outcomes
1. Define data assimilation.    
2. Generate an ecological forecast for primary productivity.    
3. Describe how to assess ecological forecast accuracy.     
4. Describe how data assimilation affects forecast accuracy and uncertainty.    
5. Explain how updating models with data collected at different time scales (e.g., daily, weekly) and with different levels of associated uncertainty affects ecological forecasts.     

## Key Concepts

### What is data assimilation?

Data assimilation is the process of updating models with data. In ecological forecasting, data assimilation is the process of updating ecological forecasting models with new environmental data as they become available.

### How does the amount of uncertainty in model predictions and data affect the process of data assimilation?

The amount of uncertainty in model predictions and data determines how much we adjust our forecasts based on new observations. For example, if we observe a new data point and we have low observation uncertainty, our forecast starting conditions will be adjusted to closely correspond to the new observation. If we observe a new data point and we have high observation uncertainty, our forecast starting conditions will not be adjusted as much.

### How does the frequency of observations affect data assimilation?

More frequent observations allow us to update our forecast models more often, potentially improving forecast accuracy.

## Overview

In this module, we will generate forecasts of lake chlorophyll-a for 1-10 days into the future. First, we will generate a 10-day forecast that does not assimilate any data. This will involve the following steps:  

1. Read in and visualize chlorophyll-a data from Lake Barco, FL, USA.  
2. Explore autocorrelation of Lake Barco chlorophyll-a data.    
3. Fit an autoregressive forecast model.   
4. Specify a distribution of forecast **initial conditions** (starting conditions). 
5. Generate a 10-day forecast with no data assimilation. 
6. Assess forecast accuracy.    

Next, we will explore the effect of **data assimilation** on forecast accuracy by conducting two data assimilation experiments. First, we will assimilate data at different temporal frequencies (e.g., daily vs. weekly) and assess the effect on forecast accuracy. Second, we will assimilate data with different levels of observation uncertainty (e.g., high vs. low observation uncertainty) and assess the effect on forecast accuracy. 

7. Assimilate data at frequencies ranging from once a week to once a day.    
8. Assess the effect of data assimilation frequency on forecast accuracy.    
9. Assimilate data with different levels of observation uncertainty.   
10. Assess the effect of observation uncertainty on forecast accuracy.   

Finally, you will be asked to summarize what you have learned about how to use data to improve ecological forecasts, and explain how data assimilation frequency and observation uncertainty are likely to affect forecast accuracy.

There are a total of XX questions embedded throughout this module, many of which parallel (and in some cases are identical to) questions in the R Shiny app version of the module. Questions which are identical to those in the Shiny app will be indicated with **(Shiny)**, while questions unique to this RMarkdown will be indicated with **(Rmd)**. Note that question numbers will differ between the RMarkdown and the Shiny app, even if the question text is the same. Please see the module rubric for possible points per question and confirm with your instructor whether and how the module will be graded.  

## Think About It!

**Q.1 (Shiny)** What is meant by the term 'data assimilation' in the context of ecological forecasting?

**Answer Q.1**



**Q.2 (Shiny)** How do you think the process of integrating the most recently observed data into models can improve forecasts?

**Answer Q.2**


## Set-up

We will install and load some packages and functions that are needed to run the module code. If you do not currently have the packages below downloaded for RStudio, you will need to install them first using the `install.packages()` function.

```{r, echo=FALSE, message = FALSE, warning=FALSE}
# install.packages("tidyverse")
# install.packages("lubridate")
# install.packages("mvtnorm")
# install.packages("zoo")
library(tidyverse)
library(lubridate)
library(zoo)

source("./Rmd_functions.R")
```

## 1. Read in and visualize data from Lake Barco, FL, USA

Lake Barco is one of the lake sites in the U.S. National Ecological Observatory Network (NEON). Please refer to https://www.neonscience.org/field-sites/barc to learn more about this site.

**Q.3 (Shiny)** Use the website linked above to fill out information about Lake Barco:

**Answer Q.3**

Four letter site identifier:  
Latitude:  
Longitude:  
Lake area (km2):  
Elevation (m):  

### Chlorophyll-a in lakes

insert section here about why chl-a matters

**Q.4 chl-a**

**Answer Q.4**



Read in and view lake chlorophyll-a data. We will rename the columns of our dataframe, and use the `cumsum()` function to filter out several rows with NA chlorophyll-a values at the beginning of our dataset. Here, the `cumsum()` function returns, at each row, the cumulative number of non-NA chl-a values up to that row. This allows us to filter out NA values at the beginning of the dataset, because as soon as the first non-NA chl-a value is observed, the `cumsum()` function will return a value greater than 0.
```{r}
lake_data <- read_csv("./data/neon/BARC_chla_microgramsPerLiter.csv", show_col_types = FALSE) %>%
  rename(datetime = Date, chla = V1) %>%
  filter(cumsum(!is.na(chla)) > 0) %>%
  mutate(chla = ifelse(chla < 0, 0, chla))

head(lake_data)
```

Plot a timeseries of chlorophyll-a observations at Lake Barco.
```{r}
plot_chla_obs(lake_data)
```

## 2. Explore autocorrelation of Lake Barco chlorophyll-a data.    

What is autocorrelation?    
What is a lag?    
Notice that we are interpolating using na.approx.   
Show plot of chla vs chla-lag and ask students if there is a relationship.  
Give equation for autocorrelation.   
Calculate autocorrelation between chla and chla-lag and ask students to interpret.   
What is partial autocorrelation and why are we using that? Don't give equation; just explain that it removes effects of observations between chla and chla at a particular lag and give R function.   
Describe pacf function and arguments.   
Calculate and plot pacf.   
Ask questions about plot interpretation.   

```{r}
forecast_start_date <- "2020-09-25"

autocorrelation_data <- lake_data %>%
    filter(datetime < forecast_start_date) %>%
    mutate(chla = na.approx(chla, na.rm = F)) %>% 
    mutate(chla_lag = lag(chla)) %>%
    filter(complete.cases(.))

ggplot(data = autocorrelation_data, aes(x = chla_lag, y = chla))+
  geom_point()+
  theme_bw()

autocorrelation_lag_1 = round(sum((autocorrelation_data$chla - mean(autocorrelation_data$chla))*(autocorrelation_data$chla_lag - mean(autocorrelation_data$chla)))/sum((autocorrelation_data$chla - mean(autocorrelation_data$chla))^2),2)

acf_list <- acf(autocorrelation_data$chla, plot = FALSE)

acf_plot_data <- tibble(Lag = acf_list$lag,
                        ACF = round(acf_list$acf, 2))

ggplot(data = acf_plot_data, aes(x = Lag, y = ACF))+
  geom_bar(stat = "identity")+
  theme_bw()

pacf_list <- acf(autocorrelation_data$chla, type = c("partial"), plot = FALSE)

pacf_plot_data <- tibble(Lag = pacf_list$lag,
                         Partial_ACF = round(pacf_list$acf, 2))

ggplot(data = pacf_plot_data, aes(x = Lag, y = Partial_ACF))+
  geom_bar(stat = "identity")+
  theme_bw()
```

## 3. Fit an autoregressive forecast model.   

What is an autoregressive model?   
Give formula for an autoregressive model, following ar.ols output.  
Explain ar.ols and why we want to use that function.   
Explain arguments of ar.ols function.  
Explain why we are logging chl-a data (to avoid negative values).  
Ask students to explain, given model function, how chl-a is being predicted.  
Explain bias and rmse as model assessment metrics.  
Ask students to assess model fit.  

```{r}
model_data <- autocorrelation_data %>%
  mutate(log_chla = log(chla + 0.001))

ar_model <- ar.ols(model_data$log_chla, order.max = 1, aic = FALSE,
                     intercept = TRUE, demean = TRUE)
ar1 = c(ar_model$ar)
chla_mean = c(ar_model$x.mean)
intercept = c(ar_model$x.intercept)
params_se <- ar_model$asy.se.coef

mod <- intercept + ar1 * (model_data$log_chla - chla_mean) + chla_mean

residuals <- mod - model_data$log_chla
err <- mean(exp(mod) - model_data$chla, na.rm = TRUE) 
rmse <- round(sqrt(mean((exp(mod) - model_data$chla)^2, na.rm = TRUE)), 2)

model_fit_plot_data <- tibble(date = model_data$datetime,
                              chla = model_data$chla,
                              model = exp(mod))

plot_mod_predictions_chla(model_fit_plot_data)

```

## 4. Specify a distribution of forecast **initial conditions** (starting conditions). 
**Initial conditions** are the starting conditions of your model when you generate a forecast. **Initial conditions uncertainty** refers to uncertainty arising because the initial conditions are not precisely known or because the calculations cannot be performed with the precise initial conditions.

Even though we have measurements of chlorophyll-a from our lake, we know that chlorophyll-a varies throughout the day so this measurement might not capture exactly the chlorophyll-a in our lake at this time. Additionally, there may be observation error in our chlorophyll-a measurements.

To account for initial conditions uncertainty we can generate a distribution around the initial condition of chlorophyll-a and then run our model with slightly different initial conditions.

Explain that we will be using high-frequency data from the previous year to get an estimate of our initial conditions uncertainty.

Need to explain rnorm function and arguments

Generate a distribution of initial conditions for your forecast using the current chlorophyll-a (`curr_chla`) and a standard deviation in units of log(ug/L) calculated from high-frequency data from Lake Barco (`ic_sd`).

```{r}
curr_chla <- log(lake_data %>%
  filter(datetime == forecast_start_date) %>%
  pull(chla))

high_frequency_data <- read_csv("./data/BARC_chla_microgramsPerLiter_highFrequency.csv", show_col_types = FALSE) %>%
  mutate(date = date(datetime)) %>%
  group_by(date) %>%
  summarize(daily_sd_chla = sd(log(chla), na.rm = TRUE))
  
ic_sd <- mean(high_frequency_data$daily_sd_chla, na.rm = TRUE)
ic_uc <- rnorm(n = 1000, mean = curr_chla, sd = ic_sd)
```

Plot the distribution around your initial condition. 

```{r}
plot_ic_dist(curr_chla, ic_uc)
```

## 5. Generate a 10-day forecast with no data assimilation. 

Here we will generate a series of 1-day-ahead forecasts. In other words, imagine that these forecasts are generated once per day, and every day, the forecast makes a prediction for tomorrow. We will "give" the forecast model a chlorophyll-a observation from Lake Barco that will be used as the initial condition for the first forecast. But after that, we will not provide any additional observations for additional forecasts. This could happen if, for example, a sensor malfunctioned and you were unable to collect data, or if you did not have a high-frequency sensor and were only able to collect 1-2 observations per month. In the absence of additional observations, the daily forecast model will simply use yesterday's forecast as the initial condition for today's forecast.

Explain each of the arguments to the EnKF in very simple terms (e.g., we need to provide the residuals of our model fit so we can account for uncertainty due to limitations in how well our model predicts chl-a)

Ask students to interpret plot.

```{r}
#set forecast horizon in days
forecast_horizon = 10

#format observation data file depending on selected frequency of data assimilation
forecast_dates <- seq.Date(from = as.Date(forecast_start_date), to = as.Date(forecast_start_date) + forecast_horizon, by = 'days')

#set chlorophyll-a assimilation frequency
chla_assimilation_frequency = 11
  
#create forecast data dataframe - ugh this needs simplified
  a <- c(1:forecast_horizon)
  b1 <- a[seq(1, length(a), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime),
           chla = log(chla)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(rownum = row_number(datetime)) %>%
    mutate(chla = ifelse(rownum %in% b1,chla,NA)) %>%
    select(-rownum)


n_en = 200 # how many ensemble members 
#run the forecast!
est_out = forecast_with_EnKF(n_en = n_en, 
                             start = forecast_start_date, # start date 
                             stop = last(forecast_dates), # stop date
                             obs_file = forecast_data,
                             obs_sd = ic_sd, 
                             yini = curr_chla,
                             model = ar_model,
                             residuals = residuals)
#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data, obs_file = forecast_data, start = forecast_start_date, stop = last(forecast_dates), n_en = n_en) 
```

## 6. Assess forecast accuracy.    

Ask students to interpret pred vs obs plot.  
Ask students to interpret forecast assessment metrics (bias and RMSE).  
```{r}
#assess forecast
pred_v_obs_chla(est_out = est_out, lake_data = lake_data)

forecast = exp(apply(est_out$Y_pred[1,,] , 1, FUN = mean))

#limit obs to forecast dates
  forecast_obs <- lake_data %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% est_out$dates) 
  
#calculate bias
err <- mean(forecast - forecast_obs$chla, na.rm = TRUE) 
#calculate RMSE
rmse <- sqrt(mean((forecast_obs$chla - forecast)^2, na.rm = TRUE))
```

## 7. Assimilate data at frequencies ranging from once a week to once a day.    

Now we will conduct an experiment to address the following question: if we had more frequent observations available to update our forecast initial conditions, how would that affect our forecast accuracy? To complete this experiment, we will generate forecasts while assimilating observations at different temporal frequencies, ranging from once a week to every day. Then, we will compare whether and how forecasts accuracy changes when we have infrequent (e.g., weekly) vs. frequent (e.g., daily) to update our forecast initial conditions.

Explain for-loop structure: looping through chla_assimilation_frequencies.  
What student questions should be included here, or should this be combined with the next section?   

```{r}
#set forecast horizon in days
forecast_horizon = 10

#format observation data file depending on selected frequency of data assimilation
forecast_dates <- seq.Date(from = as.Date(forecast_start_date), to = as.Date(forecast_start_date) + forecast_horizon, by = 'days')

#define chlorophyll-a assimilation frequency vector - once a week to once a day
chla_assimilation_frequencies = c(7:1)

#make empty list for DA frequency experiment output
da_frequency_experiment_output <- list()

for(i in 1:length(chla_assimilation_frequencies)){
  
#create forecast data dataframe
  a <- c(1:forecast_horizon)
  b1 <- a[seq(1, length(a), chla_assimilation_frequencies[i])]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime),
           chla = log(chla)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(rownum = row_number(datetime)) %>%
    mutate(chla = ifelse(rownum %in% b1,chla,NA)) %>%
    select(-rownum)


n_en = 200 # how many ensemble members 
#run the forecast!
da_frequency_experiment_output[[i]] = forecast_with_EnKF(n_en = n_en, 
                             start = forecast_start_date, # start date 
                             stop = last(forecast_dates), # stop date
                             obs_file = forecast_data,
                             obs_sd = ic_sd, 
                             yini = curr_chla,
                             model = ar_model,
                             residuals = residuals)
names(da_frequency_experiment_output)[[i]] <- paste0(chla_assimilation_frequencies[i],"_days")

}
```

## 8. Assess the effect of data assimilation frequency on forecast accuracy.

Now that we have completed our data assimilation frequency experiment, we need to assess the results

```{r}
#plot and assess weekly DA
#plot forecast output
plot_chla(est_out = da_frequency_experiment_output[[1]], lake_data = lake_data, obs_file = da_frequency_experiment_output[[1]]$obs_file, start = forecast_start_date, stop = last(forecast_dates), n_en = n_en)

#assess forecast
pred_v_obs_chla(est_out = da_frequency_experiment_output[[1]], lake_data = lake_data)

forecast = exp(apply(da_frequency_experiment_output[[1]]$Y_pred[1,,] , 1, FUN = mean))

#limit obs to forecast dates
  forecast_obs <- lake_data %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% da_frequency_experiment_output[[1]]$dates) 
  
#calculate bias
err <- mean(forecast - forecast_obs$chla, na.rm = TRUE) 
#calculate RMSE
rmse <- sqrt(mean((forecast_obs$chla - forecast)^2, na.rm = TRUE))

#plot and assess daily DA
#plot forecast output
plot_chla(est_out = da_frequency_experiment_output[[7]], lake_data = lake_data, obs_file = da_frequency_experiment_output[[7]]$obs_file, start = forecast_start_date, stop = last(forecast_dates), n_en = n_en)

#assess forecast
pred_v_obs_chla(est_out = da_frequency_experiment_output[[7]], lake_data = lake_data)

forecast = exp(apply(da_frequency_experiment_output[[7]]$Y_pred[1,,] , 1, FUN = mean))

#limit obs to forecast dates
  forecast_obs <- lake_data %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% da_frequency_experiment_output[[7]]$dates) 
  
#calculate bias
err <- mean(forecast - forecast_obs$chla, na.rm = TRUE) 
#calculate RMSE
rmse <- sqrt(mean((forecast_obs$chla - forecast)^2, na.rm = TRUE))


#money plot of all DA frequencies vs rmse
plot_da_frequency_experiment_results(da_frequency_experiment_output,
                                     chla_assimilation_frequencies)
```

## 9. Assimilate data with different levels of observation uncertainty.

```{r}
#set forecast horizon in days
forecast_horizon = 10

#format observation data file depending on selected frequency of data assimilation
forecast_dates <- seq.Date(from = as.Date(forecast_start_date), to = as.Date(forecast_start_date) + forecast_horizon, by = 'days')

#define observation uncertainty vector, with values both above and below empirically calculated observation uncertainty
obs_uncertainty = c(0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05)
  
#define chl-a assimilation frequency
chla_assimilation_frequency = 1

#create forecast data dataframe
  a <- c(1:forecast_horizon)
  b1 <- a[seq(1, length(a), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime),
           chla = log(chla)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(rownum = row_number(datetime)) %>%
    mutate(chla = ifelse(rownum %in% b1,chla,NA)) %>%
    select(-rownum)
  
n_en = 200 # how many ensemble members 


#make empty list for DA frequency experiment output
obs_uncertainty_experiment_output <- list()

for(i in 1:length(obs_uncertainty)){

#run the forecast!
obs_uncertainty_experiment_output[[i]] = forecast_with_EnKF(n_en = n_en, 
                             start = forecast_start_date, # start date 
                             stop = last(forecast_dates), # stop date
                             obs_file = forecast_data,
                             obs_sd = obs_uncertainty[i], 
                             yini = curr_chla,
                             model = ar_model,
                             residuals = residuals)
names(obs_uncertainty_experiment_output)[[i]] <- paste0(obs_uncertainty[i],"_log_ugL")

}
```


## 10. Assess the effect of observation uncertainty on forecast accuracy. 

```{r}
#plot and assess weekly DA
#plot forecast output
plot_chla(est_out = obs_uncertainty_experiment_output[[1]], lake_data = lake_data, obs_file = obs_uncertainty_experiment_output[[1]]$obs_file, start = forecast_start_date, stop = last(forecast_dates), n_en = n_en)

#assess forecast
pred_v_obs_chla(est_out = obs_uncertainty_experiment_output[[1]], lake_data = lake_data)

forecast = exp(apply(obs_uncertainty_experiment_output[[1]]$Y_pred[1,,] , 1, FUN = mean))

#limit obs to forecast dates
  forecast_obs <- lake_data %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% obs_uncertainty_experiment_output[[1]]$dates) 
  
#calculate bias
err <- mean(forecast - forecast_obs$chla, na.rm = TRUE) 
#calculate RMSE
rmse <- sqrt(mean((forecast_obs$chla - forecast)^2, na.rm = TRUE))

#plot and assess daily DA
#plot forecast output
plot_chla(est_out = obs_uncertainty_experiment_output[[10]], lake_data = lake_data, obs_file = obs_uncertainty_experiment_output[[10]]$obs_file, start = forecast_start_date, stop = last(forecast_dates), n_en = n_en)

#assess forecast
pred_v_obs_chla(est_out = obs_uncertainty_experiment_output[[10]], lake_data = lake_data)

forecast = exp(apply(obs_uncertainty_experiment_output[[10]]$Y_pred[1,,] , 1, FUN = mean))

#limit obs to forecast dates
  forecast_obs <- lake_data %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% obs_uncertainty_experiment_output[[10]]$dates) 
  
#calculate bias
err <- mean(forecast - forecast_obs$chla, na.rm = TRUE) 
#calculate RMSE
rmse <- sqrt(mean((forecast_obs$chla - forecast)^2, na.rm = TRUE))


#money plot of all DA frequencies vs rmse
plot_obs_uncertainty_experiment_results(obs_uncertainty_experiment_output,
                                     obs_uncertainty)
```