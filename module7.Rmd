---
title: "Macrosystems EDDIE Module 7: Using Data to Improve Ecological Forecasts"
author: "Mary Lofton, Tadhg Moore, Quinn Thomas, Cayelan Carey"
date: "`r Sys.Date()`"
output:
  github_document: default
---

## Purpose of this R Markdown

This R Markdown contains code to reproduce the basic functionality of "Macrosystems EDDIE Module 7: Using Data to Improve Ecological Forecasts" outside of R Shiny. The code can be used by students to better understand what is happening "under the hood" of the Shiny app, which can be found at the following link:  
https://macrosystemseddie.shinyapps.io/module7/. 

Alternatively, students can complete this version of the module instead of the Shiny app version. 

## Summary

### Focal question for this module:   

**How can we use data to improve ecological forecasts?**

To be useful for management, ecological forecasts need to be both accurate enough for managers to be able to rely on them for decision-making and include a representation of forecast uncertainty, so managers can properly interpret the probability of future events. To improve forecast accuracy, we can update forecasts with observational data once they become available, a process known as **data assimilation.** Recent improvements in environmental sensor technology and an increase in the number of sensors deployed in ecosystems have resulted in an increase in the availability of data for assimilation to help develop and improve forecasts for natural resource management. In this module, you will develop an autoregressive model of primary productivity and use the model to generate forecasts. You will then explore how assimilating data at different temporal frequencies (e.g., daily, weekly) and with different levels of observation uncertainty affects forecast accuracy. 

## Learning Outcomes
1. Define data assimilation.    
2. Generate an ecological forecast for primary productivity.    
3. Describe how to assess ecological forecast accuracy.     
4. Describe how data assimilation affects forecast accuracy and uncertainty.    
5. Explain how updating models with data collected at different time scales (e.g., daily, weekly) and with different levels of associated uncertainty affects ecological forecasts.     

## Key Concepts

### What is data assimilation?

Data assimilation is the process of updating models with data. In ecological forecasting, data assimilation is the process of updating ecological forecasting models with new environmental data as they become available.

### How does the amount of uncertainty in model predictions and data affect the process of data assimilation?

The amount of uncertainty in model predictions and data determines how much we adjust our forecasts based on new observations. For example, if we observe a new data point and we have low observation uncertainty, our forecast starting conditions will be adjusted to closely correspond to the new observation. If we observe a new data point and we have high observation uncertainty, our forecast starting conditions will not be adjusted as much.

### How does the frequency of observations affect data assimilation?

More frequent observations allow us to update our forecast models more often, potentially improving forecast accuracy.

## Overview

In this module, we will generate one-day-ahead forecasts of lake chlorophyll-a. First, we will generate forecasts that do not assimilate any data. This will involve the following steps:  

#### Activity A
Objective 1. Read in and visualize chlorophyll-a data from Lake Barco, FL, USA.  
Objective 2. Explore autocorrelation of Lake Barco chlorophyll-a data.    
Objective 3. Fit an autoregressive forecast model.   
Objective 4. Generate a one-day-ahead forecast with uncertainty.

Next, we will explore the effect of **data assimilation** on forecast output.  

#### Activity B
Objective 5. Compare one-day-ahead forecasts generated with and without data assimilation. 
Objective 6. Compare one-day-ahead forecasts generated with data assimilation, using data with low vs. high observation uncertainty.
Objective 7. Compare a series of one-day-ahead forecasts with no data assimilation, weekly data assimilation, and daily data assimilation. 

Finally, you will be asked to apply what you have learned about how data collection frequency and observation uncertainty affect data assimilation to improve forecast accuracy.

#### Activity C
Objective 8. Made management decisions using forecasts generated with different frequencies of data assimilation.

There are a total of XX questions embedded throughout this module, many of which parallel (and in some cases are identical to) questions in the R Shiny app version of the module. Questions which are identical to those in the Shiny app will be indicated with **(Shiny)**, while questions unique to this RMarkdown will be indicated with **(Rmd)**. Note that question numbers will differ between the RMarkdown and the Shiny app, even if the question text is the same. Please see the module rubric for possible points per question and confirm with your instructor whether and how the module will be graded.  

## Think About It!

**Q.1 (Shiny)** What is meant by the term 'data assimilation' in the context of ecological forecasting?

**Answer Q.1**



**Q.2 (Shiny)** How do you think the process of integrating the most recently observed data into models can improve forecasts?

**Answer Q.2**


## Set-up

We will install and load some packages and functions that are needed to run the module code. 

If you do not currently have the packages below downloaded for RStudio, you will need to install them first using the `install.packages()` function (uncomment the lines and install the packages).

We will also load some custom functions that are stored in the `Rmd_functions.R` file using the `source()` function.

```{r, echo=FALSE, message = FALSE, warning=FALSE}
# install.packages("tidyverse")
# install.packages("lubridate")
# install.packages("zoo")
# install.packages("mvtnorm")
# install.packages("see")
library(tidyverse)
library(lubridate)
library(zoo)
library(mvtnorm)
library(see)

source("./Rmd_functions.R")
```

## 1. Read in and visualize data from Lake Barco, FL, USA

Lake Barco is one of the lake sites in the U.S. National Ecological Observatory Network (NEON). Please refer to https://www.neonscience.org/field-sites/barc to learn more about this site.

**Q.3 (Shiny)** Use the website linked above to fill out information about Lake Barco:

**Answer Q.3**

Four letter site identifier:  
Latitude:  
Longitude:  
Lake area (km2):  
Elevation (m):  

### Chlorophyll-a in lakes

Chlorophyll-a concentrations are an indicator of algal (phytoplankton) abundance and biomass in a lake. Phytoplankton are important primary producers at the base of the lake food web, and are therefore necessary for healthy lake ecosystem function. However, an overabundance of phytoplankton can lead to harmful blooms. 

Blooms compromise water quality via unsightly scums, clogging of filters at water treatment plants, release of noxious taste and odor compounds, and in some cases release of toxins that pose substantial risk to human and animal health. 

Forecasts of chlorophyll-a concentrations days to weeks into the future can give water managers important information about the likelihood of a bloom event. This permits pre-emptive management to prevent or mitigate water quality concerns caused by blooms.

**Q.4 Why might a forecast of lake chlorophyll-a concentration days to weeks into the future be a useful tool for water managers?**

**Answer Q.4**



Now we will read in and view lake chlorophyll-a data. 

We will rename the columns of our dataframe, and use the `cumsum()` function to filter out several rows with NA chlorophyll-a values at the beginning of our dataset. Here, the `cumsum()` function returns, at each row, the cumulative number of non-NA chl-a values up to that row. This allows us to filter out NA values at the beginning of the dataset, because as soon as the first non-NA chl-a value is observed, the `cumsum()` function will return a value greater than 0.

Finally, we will use the `mutate()` function to set any chl-a values that are less than 0 due to sensor error to 0, as negative chl-a values (representing negative phytoplankton) are not actually possible.
```{r}
lake_data <- read_csv("./data/neon/BARC_chla_microgramsPerLiter.csv", show_col_types = FALSE) %>%
  rename(datetime = Date, chla = V1) %>%
  filter(cumsum(!is.na(chla)) > 0) %>%
  mutate(chla = ifelse(chla < 0, 0, chla))

head(lake_data)
```

Plot a timeseries of chlorophyll-a observations at Lake Barco.
```{r}
ggplot(data = lake_data, aes(x = datetime, y = chla))+
    geom_line(aes(color = "Chl-a"))+
    xlab("")+
    ylab(expression(paste("Chlorophyll-a (ug/L)")))+
    scale_color_manual(values = c("Chl-a" = "chartreuse4"), name = "")+
    theme_bw()
```

**Q.5 Describe how chlorophyll-a changes over time in Lake Barco. Do you notice any patterns or trends?**

**Answer Q.5**

## 2. Explore autocorrelation of Lake Barco chlorophyll-a data.    

### What is autocorrelation?    

**Autocorrelation** is the correspondence between a value and previous values of that variable which have been recently observed. For example, mean daily air temperature over the course of a year exhibits autocorrelation, as today's mean daily air temperature is related to the mean daily air temperatures observed over the days and weeks prior to today. 

The **incredibly useful** thing about autocorrelation from a forecasting perspective is that it allows us to use *previous or current observations* of a variable to predict *future values* of that variable - excellent!

### What is a lag?  

A **lag** is a particular amount of time that has passed between when we observe a value we are using as an explanatory, or independent, variable, and when we observe a value that we are trying to predict. For example, if you use today's air temperature to predict tomorrow's air temperature, you are using a 1-day lag of air temperature to predict tomorrow's air temperature. 

You could also use a 2-day lag of air temperature (that would be the air temperature observed yesterday), or a 3-day lag, 4-day lag, and so on..... or some combination of all of those lags, to predict tomorrow's air temperature.

In general, stronger relationships among lags of a variable leads to higher **autocorrelation** in a timeseries of that variable.

**Q.6 Explain, in your own words, how autocorrelation in a variable can help forecasters make predictions of the future.** 

**Answer Q.6**

Let's explore lags and autocorrelation in chl-a data at Lake Barco.

First, we need to do some data wrangling. We will `filter()` our dataset to only include data that are observed prior to our forecast date, which is 2020-09-25. These are the data we will eventually use to fit our forecast model.

We will also linearly interpolate missing values in our chlorophyll-a data using the `na.approx()` function, and create a column of 1-day lagged values of chlorophyll-a using the `lag()` function. 

Finally, we will double-check that we have no missing values in our dataset by using `complete.cases()` to eliminate rows with NA values. This is important because we cannot have NA values when we fit our forecasting model to our data later on.
```{r}
forecast_start_date <- "2020-09-25"

autocorrelation_data <- lake_data %>%
    filter(datetime < forecast_start_date) %>%
    mutate(chla = na.approx(chla, na.rm = F)) %>% 
    mutate(chla_lag = lag(chla)) %>%
    filter(complete.cases(.))

head(autocorrelation_data)
```

Next, we will create an example plot to illustrate the concept of a **lagged variable**. To make it easier to see the 1-day lag in chlorophyll-a on the figure, we will only plot data from the last four months in 2018.
```{r}
plot_data <- autocorrelation_data %>%
  filter(datetime > "2018-09-01" & datetime < "2018-12-31")

plot_chla_lag(plot_data)
```

**Q.7 Describe what you observe on the timeseries figure above. How do the two lines plotted on the timeseries (chlorophyll and 1 day lag of chlorophyll) relate to each other?** 

**Answer Q.7**



To visualize the relationship between chlorophyll and a 1 day lag of chlorophyll in a different way, we will also plot these two timeseries on a scatterplot. The dashed diagonal line represents the 1:1 line. The closer the points fall to this line, the stronger of the linear relationship between the independent variable (x axis) and the dependent variable (y axis).

Note that now, we are plotting the complete model fitting dataset (2017-10-21 to 2020-09-25).
```{r}
ggplot(data = autocorrelation_data, aes(x = chla_lag, y = chla))+
  geom_point()+
  xlab(expression(paste("1 day lag of chlorophyll-a (",mu,g,~L^-1,")")))+
  ylab(expression(paste("chlorophyll-a (",mu,g,~L^-1,")")))+
  geom_abline(slope = 1, intercept = 0, linetype = 2)+
  theme_bw()
```

**Q.8 Describe what you observe on the scatterplot figure above. Do you think the Lake Barco chlorophyll-a data exhibit autocorrelation? Why or why not?** 

**Answer Q.8**

 

In addition to visualizing autocorrelation, we can also calculate it. The autocorrelation between chlorophyll-a ($Chla$) and a 1-day lag of chlorophyll-a ($ChlaLag$) is represented by the following equation:

$$Autocorrelation = \frac {\sum_{t = 2}^{T} (
Chla - \overline{Chla}) * (
ChlaLag - \overline{Chla})}{\sum_{t = 1}^{T} (
Chla - \overline{Chla})^2}$$

where $T$ is the timeseries of observations in the timeseries and $t$ represents which observation in that timeseries we are starting with (either the 1st or 2nd observation). Recall that the capital sigma $(\sum)$ indicates a sum and the overline $(\overline{Chla})$ indicates the mean.

The closer the autocorrelation is to 1, the stronger the autocorrelation between the variable and its lag.

We can calculate autocorrelation in code. Note that in the following calculation, the `[-1]` eliminates the first element of `autocorrelation_data$chla` or `autocorrelation_data$chla_lag` vectors, following the $t=2$ specification for the $\sum_{t = 2}^{T}$ function in the numerator of the autocorrelation equation above.
```{r}
autocorrelation_lag1 = round(sum((autocorrelation_data$chla[-1] - mean(autocorrelation_data$chla[-1]))*(autocorrelation_data$chla_lag[-1] - mean(autocorrelation_data$chla[-1])))/sum((autocorrelation_data$chla - mean(autocorrelation_data$chla))^2),3)

autocorrelation_lag1
```

**Q.9 Interpret the value of `autocorrelation_lag1`; does this value indicate low or high autocorrelation between chlorophyll-a and a 1-day lag of chlorophyll-a?** 

**Answer Q.9**


Next, we can calculate and plot the autocorrelation values for many different lags of our chlorophyll-a data. Rather than doing this calculation step-by-step, we can use the `acf()` function to calculate the autocorrelation for many lags, and then plot them below.
```{r}
acf_list <- acf(autocorrelation_data$chla, plot = FALSE)

acf_plot_data <- tibble(Lag = acf_list$lag,
                        ACF = round(acf_list$acf, 2))

ggplot(data = acf_plot_data, aes(x = Lag, y = ACF))+
  geom_bar(stat = "identity")+
  xlab("Lag in days")+
  ylab("Autocorrelation")+
  theme_bw()
```

**Q.10 Describe how autocorrelation changes as the lag in days increases. Why do you think this pattern occurs?** 

**Answer Q.10**



**Q.11 Imagine you are asked to develop a forecasting model that uses lagged values of chlorophyll-a to predict future chlorophyll-a. Examining the autocorrelation plot above, how many lags of chlorophyll-a would you include in your forecasting model? Provide your answer in days (e.g., I would include up to a 3-day lag) and explain your reasoning.**

**Answer Q. 11**
 

As you may have discovered while answering Q.11, it can be difficult to decide exactly how many lags to include in a forecasting model. Fortunately, forecasters have developed tools to help make this decision. One such tool is the **partial autocorrelation function**, or **PACF**. This function calculates the autocorrelation of a particular lag *while removing* the effects of indirect correlations with other lags. 

To explain another way: the **autocorrelation** of chlorophyll-a and the 7-day lag of chlorophyll-a is affected by the autocorrelation of chlorophyll-a with the 1-day lag, the 2-day lag, the 3-day lag, and so on, as well as the relationship of the 7-day lag to the 1-day lag, the 2-day lag, the 3-day lag, and so on.

The PACF avoids this problem. You can think of it as only measuring the effect of one particular set of lagged values (e.g., the 5-day lagged values), while accounting for (and thereby removing the influence of) all other lags.

To calculate the PACF, we can use the same `acf()` function, while adding the argument `type = c("partial")` to indicate that we'd like to calculate the partial autocorrelation function. 
```{r}
pacf_list <- acf(autocorrelation_data$chla, type = c("partial"), plot = FALSE)

pacf_plot_data <- tibble(Lag = pacf_list$lag,
                         Partial_ACF = round(pacf_list$acf, 2))
head(pacf_plot_data)
```
Now, we can plot the PACF.
```{r}
ggplot(data = pacf_plot_data, aes(x = Lag, y = Partial_ACF))+
  geom_bar(stat = "identity")+
  xlab("Lag in days")+
  ylab("Partial autocorrelation")+
  theme_bw()
```

**Q.12 Examine the PACF plot. Which lag contributes the most to autocorrelation in the Lake Barco chlorophyll-a data? Explain how you know.**

**Answer Q. 11**



**Q.13 Once again, imagine you are asked to develop a forecasting model that uses lagged values of chlorophyll-a to predict future chlorophyll-a. Examining the PACF plot above, how many lags of chlorophyll-a would you include in your forecasting model? Provide your answer in days (e.g., I would include up to a 3-day lag) and explain your reasoning.**

**Answer Q. 13**




**Q.14 Did the number of lags you chose to include in your forecasting model change from Q.11 to Q.13? Why or why not?**

**Answer Q. 14**




## 3. Fit an autoregressive forecast model.   

### What is an autoregressive model?  

An **autoregressive model** uses past and/or current values of a variable to predict future values. In our case, we are interested in using past and current values of lake chlorophyll-a to predict future chlorophyll-a.

Today, we will fit a simple form of an autoregressive, or AR model, which uses yesterday's chlorophyll-a observation (so, a 1-day lag) to predict today's observation. This model can be written as:

$$Chla_{t} = \beta_0 + \beta_1 * (Chla_{t-1} - \overline{Chla}) + \overline{Chla}$$
where $Chla$ is our timeseries of chlorophyll-a data, $\beta_0$ is the intercept parameter, $\beta_1$ is the coefficient on the 1-day lag of chlorophyll-a, and $\overline{Chla}$ is the mean of the chlorophyll-a timeseries.

Let's fit this model to our data! 
```{r}
model_data <- autocorrelation_data 
```

To fit our model, we will use the `ar.ols()` function, which fits an autoregressive time series model to data by ordinary least squares. 

While it's possible that including additional lags besides a 1-day lag might improve our predictions, for today, we will keep it simple and just use a 1-day lag. We will specify this by adding the `order.max = 1` argument to our function. 

In addition, we will specify:

1. `aic = FALSE` because we know we only want to use the first lag, we don't need to use the AIC, or Akaike Information Criterion, to help us choose how many lags to include
2. `intercept = TRUE` we do want to fit an intercept term
3. `demean = TRUE` we do want to subtract the mean
```{r}
ar_model <- ar.ols(model_data$chla, order.max = 1, aic = FALSE,
                     intercept = TRUE, demean = TRUE)
```

Next, let's extract our model parameters and have a look at them.

First, $\beta_0$, the intercept:
```{r}
intercept = c(ar_model$x.intercept)
intercept
```

Next, $\beta_1$, the 1-day lag coefficient:
```{r}
ar1 = c(ar_model$ar)
ar1
```

Then, the mean of chlorophyll-a:
```{r}
chla_mean = c(ar_model$x.mean)
chla_mean
```

**Q.15 Explain, in your own words, how the autoregressive model you have just fitted predicts chlorophyll-a.**


**Answer Q. 15**


### How can we assess model fit?

Before we use this model for forecasting, it is a good idea to see how well it fits our data. We will use three methods for doing this:

1. Visual observation of model predictions vs. observations. This is a simple but effective method. The closer your model predictions fall to your observations, the better the model fit.
2. **Bias**: Bias is the mean difference between model predictions and observations. The smaller the absolute value of the bias, the better your model fit.
3. **Root mean square error (RMSE)**: RMSE is the mean sum of squared errors (differences between predictions and observations), and can be calculated as:

$$RMSE = \sqrt{\frac{\sum_{i=1}^{N}(Predicted_i - Observed_i)^2}{N}}$$
The closer the RMSE is to 0, the better your model fit.

First, let's use our fitted model to generate predictions.
```{r}
mod <- intercept + ar1 * (model_data$chla - chla_mean) + chla_mean
```

Next, we will create a data frame for plotting.
```{r}
model_fit_plot_data <- tibble(date = model_data$datetime,
                              chla = model_data$chla,
                              model = mod)
```

Now, we can assess our model visually. We will plot the model predictions and observations.
```{r}
plot_mod_predictions(model_fit_plot_data, variable_name = "Chlorophyll-a (ug/L)")
```

**Q.16 Use the plot above to assess the model fit to data. How well do the predictions match the observations?**


**Answer Q. 16**



Next, we will calculate bias. The units of bias are the same as the predicted variable (in our case, $\mu g L^{-1}$).
```{r}
bias <- mean(mod - model_data$chla, na.rm = TRUE) 
bias
```
**Q.17 Use the calculated bias to assess the model fit to data. How good is the model fit? Explain your reasoning.**


**Answer Q. 17**



Finally, we will calculate RMSE. The units of RMSE are also the same as the predicted variable.
```{r}
rmse <- round(sqrt(mean((mod - model_data$chla)^2, na.rm = TRUE)), 2)
rmse
```
**Q.18 Use the calculated RMSE to assess the model fit to data. How good is the model fit? Explain your reasoning.**

**Answer Q. 18**



We will also save the **residuals** of our model, which are the differences between model predictions and observations. We will need these values later on to account for **process uncertainty**, or uncertainty due to the structure of our model, in our forecasts.
```{r}
residuals <- mod - model_data$chla
```


## 4. Generate a one-day-ahead forecast with uncertainty.

Finally, we are ready to generate a forecast with our fitted model! 

### A note on shifting from model fitting to forecasting
So far, we have fit our chlorophyll-a model using yesterday's chlorophyll-a to predict today's chlorophyll-a. 
 
Now, to forecast, we will need to make a subtle but important change in the way we write our model, to show that instead of predicting today's chlorophyll-a, we are now forecasting tomorrow's chlorophyll-a:

$$Chla_{t+1} = \beta_0 + \beta_1 * (Chla_{t1} - \overline{Chla}) + \overline{Chla}$$
Note the change in the subscripts of the Chla variables from t-1 to t and t to t+1!!

To generate a forecast using our model, we use today's observation to make a prediction for tomorrow. But before we can do that, we need to calculate the uncertainty associated with our forecast.

### What is ecological forecast uncertainty? 

Forecast uncertainty is the range of possible alternate future conditions predicted by a model. We generate multiple different predictions of the future because the future is inherently unknown.  

### Where does ecological forecast uncertainty come from?

Uncertainty comes from natural variability in the environment, imperfect representation of an ecological system in a model, and error when measuring the system. When generating a forecast, uncertainty can come from the structure of the model used, the initial conditions of the model, the parameters of the model, and the data used to drive the model, among other sources.

### Why is uncertainty important to quantify for an ecological forecast? 

Knowing the uncertainty in a forecast allows forecast users to make informed decisions based on the range of forecasted outcomes and prepare accordingly.

### What is an ensemble forecast?
One way of accounting for uncertainty in forecasts is through an **ensemble forecast**. Ensemble forecasts are generated by running a model many times with different conditions. In our case, we will run our autoregressive model many times with slightly different conditions to account for uncertainty in the forecast. All the model runs together are referred to as the **ensemble**. Each individual model run is referred to as an **ensemble member**. Forecasters typically generate tens to hundreds of ensemble members to build uncertainty into their forecasts.  

We will set the number of ensemble members we would like to have in our ensemble forecast.
```{r}
n_members = 500
```


**Q.XX** Explain, in your own words, what forecast uncertainty is and why it is important to account for uncertainty in forecasts.

**Answer Q.XX**



### Sources of forecast uncertainty

There are multiple sources of uncertainty in forecasts. Today, we will be accounting for two sources of forecast uncertainty: **initial conditions uncertainty** and **process uncertainty**.

#### What are forecast **initial conditions**?

**Initial conditions** are the starting conditions of your model when you generate a forecast. 

#### What is **initial conditions uncertainty**?

**Initial conditions uncertainty** refers to uncertainty arising because the current conditions in an ecosystem - in our case, lake chlorophyll-a - are not precisely known.

Even though we have measurements of chlorophyll-a from our lake, we know that chlorophyll-a varies throughout the day so this measurement might not capture exactly the chlorophyll-a in our lake at this time. Additionally, there may be observation error in our chlorophyll-a measurements.

To account for initial conditions uncertainty we can generate a distribution around the initial condition of chlorophyll-a and then run our model with slightly different initial conditions.


**Q.19** What data from Lake Barco are needed to provide the initial condition for your forecast model? 

**Answer Q.19**



So far, we have been working with daily mean chlorophyll-a values from Lake Barco to fit our model and generate a deterministic forecast.

Now, we will use some high-frequency (5-minute) chlorophyll-a data from our lake to estimate initial conditions uncertainty. For ease of visualization, we will only look at data from 2019-10-09 to 2019-10-12.
```{r}
high_frequency_data <- read_csv("./data/BARC_chla_microgramsPerLiter_highFrequency.csv", show_col_types = FALSE) %>%
  mutate(date = date(datetime),
         time = hms::as_hms(datetime)) %>%
  filter(date >= "2019-10-09" & date <= "2019-10-12")
```
We can look at variability in this 5-minute data over the course of a day to get a visual understanding of the daily variability in chlorophyll-a. Each colored line in the plot below represents a different day of chl-a data from midnight to midnight. 
```{r}
ggplot(data = high_frequency_data)+
  geom_line(aes(x = time, y = chla, group = date, color = as.factor(date)))+
  theme_bw()+
  labs(color = "Date")+
  xlab("Hour of day")+
  ylab("Chlorophyll-a (ug/L)")
```

**Q.20** Examine the plot of high-frequency chlorophyll-a data. How variable is chlorophyll-a over the course of a day? 

**Answer Q.20**



**Q.21** Recall that we are using the daily mean of chlorophyll-a as the initial condition for our model. Given the daily variability that you see in the high-frequency chlorophyll-a data, do you think that using a daily mean is a good representation of daily chlorophyll-a in Lake Barco? Explain your reasoning.

**Answer Q.21**




Next, we will calculate the mean daily standard deviation of chl-a measurements (`ic_sd`), which we will use to estimate uncertainty in our initial conditions. 
```{r}
ic_sd_dataframe <- high_frequency_data %>%
  group_by(date) %>%
  summarize(daily_sd_chla = sd(chla, na.rm = TRUE))
  
ic_sd <- mean(ic_sd_dataframe$daily_sd_chla, na.rm = TRUE)
ic_sd
```


Now, we can generate a distribution of initial conditions for our forecast using the current chlorophyll-a (`curr_chla`) and a standard deviation in units of ug/L calculated from high-frequency data from Lake Barco (`ic_sd`).

To do this, we will use the `rnorm()` function, which takes `n` draws from a normal distribution with a `mean` and `sd` specified as arguments to the function.
```{r}
curr_chla <- lake_data %>%
  filter(datetime == forecast_start_date) %>%
  pull(chla)

ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
```

Plot the distribution around your initial condition. This represents the **initial conditions uncertainty** of your forecast.
```{r}
plot_ic_dist(curr_chla, ic_distribution)
```

#### What is **process uncertainty** in an ecological forecast?

Process uncertainty is uncertainty caused by our inability to model all processes as observed in the real world.

Our 'simple' chlorophyll-a model uses today's chlorophyll-a to forecast tomorrow's chlorophyll-a. For example:

$$Chla_{t+1} = \beta_0 + \beta_1 * (Chla_{t1} - \overline{Chla}) + \overline{Chla}$$ 
But we know that chlorophyll-a can be affected by other processes as well (such as water temperature and the amount of available light and nutrients) and that our model has simplified or ignored these. To account for the uncertainty these simplifications introduce, we can add in process noise (W) at each time step. In this model, chlorophyll-a tomorrow is a function of today's chlorophyll-a plus some noise (W):

$$Chla_{t+1} = \beta_0 + \beta_1 * (Chla_{t1} - \overline{Chla}) + \overline{Chla} + W$$
where process noise is equal to a random number drawn from a normal distribution with a mean of zero and a standard deviation ($\sigma$).

$$W \sim {\mathrm Norm}(0, \sigma)$$

To account for process uncertainty, we can run the model multiple times with random noise added to each model run. More noise is associated with higher process uncertainty, and vice versa. But how much random noise should we add?

To calculate process uncertainty, we will define the standard deviation of the process uncertainty distribution, `sigma` as the standard deviation of the residuals. This is the uncertainty left over after we found the best parameters for fitting the model.

```{r}
sigma <- sd(residuals, na.rm = TRUE) # Process Uncertainty Noise Std Dev.; this is your sigma
```

Use `rnorm()` your process uncertainty distribution, using 0 as the mean and `sigma` as the standard deviation.
```{r}
process_distribution <- rnorm(n = n_members, mean = 0, sd = sigma)
```

Plot the process uncertainty distribution. We will use this distribution to account for uncertainty in our forecast.
```{r}
plot_process_dist(process_distribution)
```

Finally, we are ready to use our autoregressive model to generate a one-day-ahead forecast with uncertainty. Notice that we are using our initial condition and process uncertainty distributions to run our model many times with slightly different random noise (W) and initial conditions values. This allows us to account for uncertainty in our forecast.
```{r}
forecast_chla = intercept + ar1 * (ic_distribution - chla_mean) + chla_mean + process_distribution
```

Let's take a look at our forecast for tomorrow with uncertainty!
```{r}
plot_fc_dist(forecast_chla)
```


To prepare you for our next activity, let's visualize this forecast in a different way, using a customized plotting function. We will use plots very similar to this one to help explain the process of data assimilation later on.

First we will define some arguments for the function:
1. `start_date` date forecast is generated
2. `forecast_date` date being forecasted
```{r}
start_date <- "2020-09-25" 
forecast_date <- "2020-09-26"
```

Plot the forecast.
```{r}
plot_fc_1day(curr_chla, start_date, forecast_date, ic_distribution, forecast_chla, n_members)
```

**Q.XX** What is the forecasted chlorophyll-a concentration for Sept. 26, 2020? 

*Hint: Remember, because forecasts are uncertain, there is not one single correct value for forecasted chlorophyll-a.*

**Answer Q.XX**



**Q.XX** What is the relationship between the observed chlorophyll-a for Sept. 25, 2020, and the initial condition distribution (shown in blue)?

**Answer Q.XX**



**Q.XX** Each one of the gray lines in the figure above represents an ensemble member. Explain what this means in your own words, with specific reference to the autoregressive model we are using for forecasting in this exercise.

**Answer Q.XX**


To learn more about forecast uncertainty, you can explore Macrosystems EDDIE Module 6: Understanding Uncertainty in Ecological Forecasts, which is available both as an [R Shiny app](https://macrosystemseddie.shinyapps.io/module6/) and as an [RMarkdown](https://github.com/MacrosystemsEDDIE/module6_R).

## Activity B

## 5. Compare one-day-ahead forecasts generated with and without data assimilation.

Now that we have generated a forecast with uncertainty, we are going to explore the effect of data assimilation on our forecast. Remember, **data assimilation** is the process of using observed data to update our forecast model as the data become available.

Let's pretend that a day has passed since we made our first forecast, and we now have a new observation that we can use to update our forecast.
```{r}
new_obs <- lake_data %>%
  filter(datetime == forecast_date) %>%
  pull(chla)
```

We will use this observation to update our forecast **initial condition**. We will do this using a statistical technique called an **ensemble Kalman filter**. 

#### What is an ensemble Kalman filter?

An **ensemble Kalman filter** is a statistical technique that updates model predictions to more closely match the most recently observed data, while accounting for uncertainty in both model predictions and observations. While there are many techniques that can be used to assimilate data in ecological forecasts, the benefits of an ensemble Kalman filter are:

1. It is designed to be used with model ensembles, and so is an ideal method for ensemble forecasts which account for uncertainty.

2. It accounts for uncertainty in both model predictions and observations, rather than assuming that observations are "true" and have no uncertainty.

3. It can be used to update multiple variables and parameters within a model, even if not all of the variables and parameters are observed. For example, suppose you have a model that predicts both water temperature and air temperature, but you only have observations of water temperature. An ensemble Kalman filter can use the relationship between water and air temperature in the model to update both variables as well as relevant model parameters using just the water temperature observations.

For today, we will use a simplified version of the ensemble Kalman filter that just updates the initial condition of chlorophyll-a with new observations when they become available. We have built a custom function called `EnKF()` that runs the simplified ensemble Kalman filter. If you would like to examine the contents of this function and learn more about how the ensemble Kalman filter works, the source code for the `EnKF()` function can be found in the `Rmd_functions.R` file in the module assignment folder.

**Q.XX** Briefly describe in your own words how an ensemble Kalman filter can be used to assimilate data into an ecological forecast.

**Answer Q.XX**


To run the custom `EnKF()` function, we need to supply three arguments:

1. `forecast_chla` a forecast of chlorophyll-a, in the form of a distribution that accounts for uncertainty in model predictions
2. `new_obs` a new observation we will use to update the forecast
3. `ic_sd` the standard deviation of our initial conditions distribution, so the ensemble Kalman filter can account for uncertainty of the new observation

Update the forecast initial condition using the new observation.
```{r}
ic_update <- EnKF(forecast = forecast_chla, new_observation = new_obs, ic_sd = ic_sd)
```

Let's plot the updated initial condition! We will also plot the initial forecast again for comparison.
```{r}
chla_obs <- c(curr_chla, new_obs) #vector of observations to use for plotting
plot_fc_1day(curr_chla, start_date, forecast_date, ic_distribution, forecast_chla, n_members)
plot_fc_update(chla_obs, start_date, forecast_date, ic_distribution, ic_update, forecast_chla, n_members)
```

**Q.XX** Compare the difference between the forecast distribution (white distribution) for 2020-09-26 and the updated initial condition (blue distribution) for 2020-09-26. How are these two distributions different?

**Answer Q.XX**


**Q.XX** The initial condition for 2020-09-26 has been updated using the most recent observation (yellow dot for 2020-09-26). Why isn't the updated initial condition for 2020-09-26 (blue distribution) centered exactly on the new observation? 

**Answer Q.XX**


Now we will make a second forecast for the next day using our updated initial conditions.
```{r}
second_forecast_date <- "2020-09-27"
second_forecast = intercept + ar1 * (ic_update - chla_mean) + chla_mean + process_distribution
```

Finally, we will plot both of our forecasts together with the initial conditions for each forecast. We will also plot the observation for 2020-09-27 so we can visually assess the accuracy of our second forecast.
```{r}
forecast_dates = c(forecast_date, second_forecast_date) #vector of forecast dates
plot_second_forecast(chla_obs, start_date, forecast_dates, ic_distribution, ic_update, forecast_chla, second_forecast, n_members)
```

**Q.XX** What is the forecasted chlorophyll-a for 2020-09-27?

**Answer Q.XX**



We have explored how the ensemble Kalman filter can update the forecast initial condition using a new observation. But what if there is no observation to use for updating? What will be the outcome of the applying the ensemble Kalman filter in this situation?

First we set the new observation to NA.
```{r}
missing_obs <- NA
```

Now we will run the ensemble Kalman filter with an NA instead of an observation.
```{r}
ic_update_no_obs <- EnKF(forecast = forecast_chla, new_observation = missing_obs, ic_sd = ic_sd)
```

Let's plot the outcome. We will also plot the initial forecast again for comparison.
```{r}
chla_obs_missing <- c(curr_chla, missing_obs) #vector of observations to use for plotting
plot_fc_1day(curr_chla, start_date, forecast_date, ic_distribution, forecast_chla, n_members)
plot_fc_update(chla_obs_missing, start_date, forecast_date, ic_distribution, ic_update_no_obs, forecast_chla, n_members)
```

**Q.XX** Compare the difference between the forecast distribution (white distribution) for 2020-09-26 and the updated initial condition (blue distribution) for 2020-09-26. How are these two distributions different?

**Answer Q.XX**


**Q.XX** In this case, the observation for 2020-09-26 was missing. How did this affect the updated initial condition for 2020-09-26, compared to when an observation was available? 

**Answer Q.XX**


Now we will make a second forecast. You have seen that when an observation is missing, the initial condition cannot be updated. Let's see how this affects the second forecast.
```{r}
second_forecast_no_obs = intercept + ar1 * (ic_update_no_obs - chla_mean) + chla_mean + process_distribution
```

Finally, we will plot both of our forecasts together with the initial conditions for each forecast.
```{r}
plot_second_forecast(chla_obs_missing, start_date, forecast_dates, ic_distribution, ic_update_no_obs, forecast_chla, second_forecast_no_obs, n_members)
```

**Q.XX** What is the forecasted chlorophyll-a for 2020-09-27?

**Answer Q.XX**


**Q.XX** Compare the two-forecast plot with no data assimilation (missing observation) to the two-forecast plot with data assimilation. Specifically, how do the forecasts for 2020-09-27 on each plot compare?

**Answer Q.XX**




## 6. Compare one-day-ahead forecasts generated with data assimilation, using data with low vs. high observation uncertainty.

We have explored the effect of data assimilation vs. no data assimilation on forecasts using an ensemble Kalman filter, which accounts for uncertainty in both model predictions and observations. 

Now, imagine that we have purchased a new water quality sensor, which takes incredibly accurate chlorophyll-a measurements, thus decreasing our observation uncertainty. How might this decrease in observation uncertainty affect our forecasts?

**Q.XX** Make a prediction. How do you think a decrease in observation uncertainty will affect the forecasts?

**Answer Q.XX**


First, let's plot an initial conditions distribution that reflects the lower uncertainty due to our new water quality sensor.
```{r}
ic_sd_low = 0.1
ic_distribution_low <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd_low)
plot_ic_dist(curr_chla, ic_distribution_low)
```

Now, we will replicate the two-forecast plot with data assimilation that we created above, but this time with lower observation uncertainty.

Generate the first forecast (for 2020-09-26).

```{r}
first_forecast_low_obs_uc = intercept + ar1 * (ic_distribution_low - chla_mean) + chla_mean + process_distribution
```

Update the initial condition using the ensemble Kalman filter. *Note* we are specifying the `ic_sd` argument to the `EnKF()` function as the new, lower initial condition standard deviation (`ic_sd_low`) due to the lower observation uncertainty from our new water quality sensor.

```{r}
ic_update_low_obs_uc <- EnKF(forecast = first_forecast_low_obs_uc, new_observation = new_obs, ic_sd = ic_sd_low)
```

Generate a second forecast (for 2020-09-27) using the updated initial condition with lower observation uncertainty.

```{r}
second_forecast_low_obs_uc = intercept + ar1 * (ic_update_low_obs_uc - chla_mean) + chla_mean + process_distribution
```

Finally, we will plot both of our forecasts together with the initial conditions for each forecast. We will also plot the previous forecasts you made with data assimilation for comparison.

Figure A: Forecast with `ic_sd` of ~0.3 ug/L.
```{r}
plot_second_forecast(chla_obs, start_date, forecast_dates, ic_distribution, ic_update, forecast_chla, second_forecast, n_members)
```

Figure B: Forecast with `ic_sd_low` of 0.1 ug/L.
```{r}
plot_second_forecast(chla_obs, start_date, forecast_dates, ic_distribution_low, ic_update_low_obs_uc, first_forecast_low_obs_uc, second_forecast_low_obs_uc, n_members)
```

**Q.XX** Compare the initial conditions distributions (blue) in Figure A above with those in Figure B. Describe how they differ.

**Answer Q.XX**



**Q.XX** What is the effect of a decrease in observation uncertainty on the forecasts? Does this match what you predicted in Q.XX? 

**Answer Q.XX**



Now, imagine that our water quality sensor has malfunctioned (oh no!) leading to higher-than-normal observation uncertainty in our chlorophyll-a observations. 

**Q.XX** Make a prediction. Using your experience from the previous example, how do you think an increase in observation uncertainty will affect the forecasts?

**Answer Q.XX**



Let's plot an initial conditions distribution with high uncertainty.
```{r}
ic_sd_high = 0.5
ic_distribution_high <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd_high)
plot_ic_dist(curr_chla, ic_distribution_high)
```

We will once again replicate the two-forecast plot with data assimilation that we created above, but this time with higher observation uncertainty.

Generate the first forecast (for 2020-09-26).

```{r}
first_forecast_high_obs_uc = intercept + ar1 * (ic_distribution_high - chla_mean) + chla_mean + process_distribution
```

Update the initial condition using the ensemble Kalman filter. *Note* we are specifying the `ic_sd` argument to the `EnKF()` function as the new, higher initial condition standard deviation (`ic_sd_high`) due to the higher observation uncertainty from our malfunctioning water quality sensor.

```{r}
ic_update_high_obs_uc <- EnKF(forecast = first_forecast_high_obs_uc, new_observation = new_obs, ic_sd = ic_sd_high)
```

Generate a second forecast (for 2020-09-27) using the updated initial condition with higher observation uncertainty.

```{r}
second_forecast_high_obs_uc = intercept + ar1 * (ic_update_high_obs_uc - chla_mean) + chla_mean + process_distribution
```

Finally, we will plot both of our forecasts together with the initial conditions for each forecast. We will also plot the previous forecasts you made with data assimilation for comparison.

Figure C: Forecast with `ic_sd` of ~0.3 ug/L.
```{r}
plot_second_forecast(chla_obs, start_date, forecast_dates, ic_distribution, ic_update, forecast_chla, second_forecast, n_members)
```

Figure D: Forecast with `ic_sd_high` of 0.5 ug/L.
```{r}
plot_second_forecast(chla_obs, start_date, forecast_dates, ic_distribution_high, ic_update_high_obs_uc, first_forecast_high_obs_uc, second_forecast_high_obs_uc, n_members)
```

**Q.XX** Compare the initial conditions distributions (blue) in Figure C above with those in Figure D. Describe how they differ.

**Answer Q.XX**



**Q.XX** What is the effect of an increase in observation uncertainty on the forecasts? Does this match what you predicted in Q.XX? 

**Answer Q.XX**




## 7. Compare a series of one-day-ahead forecasts with no data assimilation, weekly data assimilation, and daily data assimilation. 

In the previous two objectives, we have been developing an intuition of how data assimilation works for an ecological forecast, and how observation uncertainty affects data assimilation and forecast output. Now, we will explore the effect of data assimilation on forecast accuracy - does going to the effort of collecting lots of data and assimilating it into our predictions really improve our forecasts?

To answer this question, we will generate multiple series of one-day-ahead forecasts over a period of 10 days. For each series of forecasts, we will assimilate data at different time intervals (one series with no data assimilation, one series with weekly data assimilation, and one series with daily data assimilation) and compare the accuracy of the resulting forecasts.

To do this in code, we will use a **for-loop**.

#### What is a for-loop?

A **for-loop** runs a section of code repeatedly. The number of times the for-loop runs is specified by the coder, either by specifying the number of times the code should be run before the for-loop stops. For example, below we write a for-loop that prints "Hello World!" eight times.
```{r}
for(i in 1:8){
  print("Hello World!")
}
```
**Notice:**      
1. We specify the number of times the for-loop should run with the code `for(i in 1:8)`. We will explain what the `i` refers to when we discuss indexing below.  
2. The code that is repeatedly run is contained in brackets `{}`.

#### What is indexing in a for-loop?

Within a for-loop, **indexing** allows you to refer to a particular iteration, or individual code run, of the loop. This can be useful if you want to, for example, perform a particular calculation on every row of a data frame. In R, `i` is commonly used for indexing in for-loops. Below we write a for-loop that prints the numbers 1 to 8 using indexing.
```{r}
for(i in 1:8){
  print(i)
}
```
#### How is indexing in a for-loop useful for ecological forecasting?
  
Often, we want to run a forecast model repeatedly to make predictions for multiple days into the future. For-loops can be a useful way to accomplish this, *particularly* if each day's prediction depends on the previous day.  
  
Let's pretend we have a very simple forecast model, where tomorrow's chlorophyll-a is equal to today's chlorophyll-a + 1 microgram per liter. If we wanted to generate a 7-day prediction of chlorophyll-a using this model, we could write a for-loop to do so.  
  
First, we set our initial observed chlorophyll-a.

```{r}
starting_chla <- 11.4 #micrograms per liter
```

Then, we create an empty vector in which we will store our starting chlorophyll-a as well as our predicted chlorophyll-a for the next seven days (so the total length of the vector = 8 days).

```{r}
chla <- rep(NA, 8)
```

Next, we set the first element of our empty vector to be the starting chlorophyll-a.

```{r}
chla[1] <- starting_chla
chla
```

Finally, we run a for-loop to generate 7 days of chlorophyll-a predictions, which will be stored in the `chla` vector. **Note** that the for-loop starts at the 2nd iteration (`for(i in 2:8)`) because we already know today's chlorophyll-a, so we are starting with tomorrow's prediction.

```{r}
for(i in 2:8){
  chla[i] = chla[i-1] + 1 #micrograms per liter
  print(chla[i])
}
```
  
**Q.XX (Rmd)** Can you alter the code below to generate a **10-day** prediction of chlorophyll-a rather than a 7-day prediction? What is the predicted chlorophyll-a on the 10th day?  
  
**Answer Q.XX** Edit the code block to provide your answer.
```{r}
starting_chla <- 11.4 #degrees C

chla <- rep(NA, 8)

chla[1] <- starting_chla
chla

for(i in 2:8){
  chla[i] = chla[i-1] + 1 #micrograms per liter
  print(chla[i])
}
```
  
Of course, this is probably not a very good model for predicting chlorophyll-a, because it would lead to chlorophyll-a increasing infinitely into the future! Next, we will use the concept of a for-loop to make multiple, 1-day-ahead forecasts of chlorophyll-a using the autoregressive model you fit above.

First, we will specify how many 1-day-ahead forecasts we would like to make.
```{r}
days_to_forecast = 10
```

Then we will create a date vector of our forecast start dates, based on how many days we would like to forecast.
```{r}
forecast_dates <- seq.Date(from = as.Date(forecast_start_date), to = as.Date(forecast_start_date) + days_to_forecast, by = 'days')
```

Next, we need to specify how often we want the forecast model to assimilate data. For this first series of forecasts, we want to see what happens when no data is assimilated during the forecast period (which is 10 days). So, we will set the `chla_assimilation_frequency` to 11 days, ensuring that no data will be assimilated during the 10-day forecast period.
```{r}
chla_assimilation_frequency_no_da = 11
```

Before we run the forecast, we need to format our lake data to play nicely with our forecasting function. First, we will create a vector (`chla_assimilation_dates`) that we will use as an index to be sure that we only provide the model with the chlorophyll-a data that we want to assimilate. In this case, only the observation on the first day of the forecast period will be provided as the initial condition for the forecast. 
```{r}
chla_assimilation_dates_no_da <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency_no_da)]
```

Then, we will manipulate our lake data to create a `forecast_data` dataframe, which is the data that will be provided to the model for forecasting.
```{r}
forecast_data_no_da <- lake_data %>%
  select(datetime, chla) %>%
  mutate(datetime = as.Date(datetime)) %>%
  filter(datetime %in% forecast_dates) %>%
  mutate(chla = ifelse(datetime %in% chla_assimilation_dates_no_da,chla,NA)) 
```

Next, we will create a data frame (`forecast_series_no_da`) to hold the initial conditions and forecasts for each day in our forecast period. This data frame has four columns:
1. `date` the dates for which we are generating initial conditions and/or forecasts
2. `chla` values of chlorophyll-a for our initial conditions and forecasts
3. `ensemble_member` numeric identifiers for each member of our ensemble forecast
4. `data_type` a categorical variable that can take the value "fc" to indicate that this chlorophyll-a value is part of a forecast or "ic" to indicate that this chlorophyll-a value is part of an initial conditions distribution
```{r}
forecast_series_no_da <- tibble(date = rep(forecast_dates, each = n_members*2),
              chla = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Finally, we will populate our `forecast_series_no_da` data frame with the initial conditions distribution for the very first day of the forecast period. First, we will assign the first initial conditions distribution for this series of forecasts to be the original initial conditions distribution that we created using high-frequency data from Lake Barco. 
```{r}
ic_distribution_no_da <- ic_distribution #assign the first initial conditions distribution
```

Next, we will create a temporary data frame for the initial conditions distribution that matches the format of `forecast_series_no_da`.
```{r}
temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              chla = ic_distribution_no_da,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))
```

Then, we update the relevant rows of the `forecast_series_no_da` data frame with the values of `ic_distribution_no_da` using the `rows_update()` function. This function will also be used the forecasting for-loop we will build below. 
```{r}
forecast_series_no_da <- forecast_series_no_da %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```

Finally, we run our series of forecasts! Here, we loop through days in our forecast period and generate 1-day-ahead predictions with our autoregressive model. Note we use the `rows_update()` function to replace NAs with forecasted chlorophyll-a and updated initial condition values each day.
```{r}
for(i in 2:length(forecast_dates)){
  
  #Generate forecast
  forecast_chla_no_da = intercept + ar1 * (ic_distribution_no_da - chla_mean) + chla_mean + process_distribution

  #Select current row of forecast_data to see if there is data to use for updating
  new_obs_no_da <- forecast_data_no_da$chla[i] #Observed chl-a

  #Update the initial condition
  ic_update_no_da <- EnKF(forecast = forecast_chla_no_da, new_observation = new_obs_no_da, ic_sd = ic_sd)
  
  #Assign the updated initial condition to be used for the next day's forecast
  ic_distribution_no_da <- ic_update_no_da

  #Build temporary data frame to hold current initial condition and forecast
  temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               chla = c(forecast_chla_no_da, ic_update_no_da),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

  #Update rows of forecast series output data frame
  forecast_series_no_da <- forecast_series_no_da %>%
    rows_update(temp, by = c("date","ensemble_member","data_type"))
}
```

Let's plot our series of 1-day-ahead forecasts with no data assimilation.
```{r}
plot_many_forecasts(forecast_data = forecast_data_no_da, forecast_series = forecast_series_no_da)
```

**Q.XX** Describe how the mean value of the 1-day-ahead forecasts changes over time when no data is assimilated. 

**Answer Q.XX**



**Q.XX** Describe how the uncertainty distribution of the 1-day-ahead forecasts changes over time when no data is assimilated.

**Answer Q.XX**



Now, we will assess the performance of the series of forecasts with no data assimilation.

To compare our forecasts to observations, we will first calculate the mean prediction for each day.
```{r}
forecast_means_no_da <- forecast_series_no_da %>%
  filter(data_type == "fc") %>%
  group_by(date) %>%
  summarize(forecast_mean = mean(chla, na.rm = TRUE))
```

We will also create a data frame of chlorophyll-a observations from Lake Barco that are available for our forecast period.
```{r}
chla_observations <- lake_data %>%
  filter(datetime %in% forecast_dates)
```

Then, we will plot the forecasts again, this time with the observations that occurred during the forecast period.
```{r}
plot_many_forecasts_with_obs(forecast_data = forecast_data_no_da, forecast_series = forecast_series_no_da, chla_observations = chla_observations)
```

**Q.XX** Using the plot above, visually assess the forecasts and describe their accuracy. How well do they match observations? 

**Answer Q.XX**



Next, we will calculate the bias and RMSE of our forecasts. Remember, a smaller bias or RMSE indicates a more accurate forecast.
```{r}
bias_no_da <- mean(forecast_means_no_da$forecast_mean - chla_observations$chla, na.rm = TRUE) 
bias_no_da

rmse_no_da <- round(sqrt(mean((forecast_means_no_da$forecast_mean - chla_observations$chla)^2, na.rm = TRUE)), 2)
rmse_no_da
```

**Q.XX** Use the values of bias and RMSE to assess the forecasts with no data assimilation. How well are the forecasts performing?

**Answer Q.XX**



Now, we will compare our series of 1-day-ahead forecasts with no data assimilation to forecasts made with weekly data assimilation.

Let's run the forecasts with weekly data assimilation.

We will change our assimilation frequency to weekly. 
```{r}
chla_assimilation_frequency_weekly = 7
```

We will update our vector of chlorophyll-a data assimilation dates.
```{r}
chla_assimilation_dates_weekly <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency_weekly)]
```

Then, we will manipulate our lake data to create a `forecast_data` dataframe, which is the data that will be provided to the model for forecasting.
```{r}
forecast_data_weekly <- lake_data %>%
  select(datetime, chla) %>%
  mutate(datetime = as.Date(datetime)) %>%
  filter(datetime %in% forecast_dates) %>%
  mutate(chla = ifelse(datetime %in% chla_assimilation_dates_weekly,chla,NA)) 
```

Next, we will create a data frame (`forecast_series_weekly`) to hold the initial conditions and forecasts for each day in our forecast period. 
```{r}
forecast_series_weekly <- tibble(date = rep(forecast_dates, each = n_members*2),
              chla = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Finally, we will populate our `forecast_series_weekly` data frame with the initial conditions distribution for the very first day of the forecast period. 
```{r}
ic_distribution_weekly <- ic_distribution #assign the first initial conditions distribution

temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              chla = ic_distribution_weekly,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))

forecast_series_weekly <- forecast_series_weekly %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```

Finally, we run our series of forecasts! Here, we loop through days in our forecast period and generate 1-day-ahead predictions with our autoregressive model. 
```{r}
for(i in 2:length(forecast_dates)){
  
  #Generate forecast
  forecast_chla_weekly = intercept + ar1 * (ic_distribution_weekly - chla_mean) + chla_mean + process_distribution

  #Select current row of forecast_data to see if there is data to use for updating
  new_obs_weekly <- forecast_data_weekly$chla[i] #Observed chl-a

  #Update the initial condition
  ic_update_weekly <- EnKF(forecast = forecast_chla_weekly, new_observation = new_obs_weekly, ic_sd = ic_sd)
  
  #Assign the updated initial condition to be used for the next day's forecast
  ic_distribution_weekly <- ic_update_weekly

  #Build temporary data frame to hold current initial condition and forecast
  temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               chla = c(forecast_chla_weekly, ic_update_weekly),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

  #Update rows of forecast series output data frame
  forecast_series_weekly <- forecast_series_weekly %>%
    rows_update(temp, by = c("date","ensemble_member","data_type"))
}
```

Let's plot our series of 1-day-ahead forecasts with weekly data assimilation.
```{r}
plot_many_forecasts(forecast_data = forecast_data_weekly, forecast_series = forecast_series_weekly)
```

**Q.XX** Describe how the mean value of the 1-day-ahead forecasts changes over time with weekly data assimilation. 

**Answer Q.XX**



**Q.XX** Describe how the uncertainty distribution of the 1-day-ahead forecasts changes over time with weekly data assimilation.

**Answer Q.XX**



Now, we will assess the performance of the series of forecasts with weekly data assimilation.

To compare our forecasts to observations, we will first calculate the mean prediction for each day.
```{r}
forecast_means_weekly <- forecast_series_weekly %>%
  filter(data_type == "fc") %>%
  group_by(date) %>%
  summarize(forecast_mean = mean(chla, na.rm = TRUE))
```

Then, we will plot the forecasts again, this time with the observations that occurred during the forecast period.
```{r}
plot_many_forecasts_with_obs(forecast_data = forecast_data_weekly, forecast_series = forecast_series_weekly, chla_observations = chla_observations)
```

**Q.XX** Using the plot above, visually assess the forecasts and describe their accuracy. How well do they match observations? 

**Answer Q.XX**



Next, we will calculate the bias and RMSE of our forecasts. Remember, a smaller bias or RMSE indicates a more accurate forecast.
```{r}
bias_weekly <- mean(forecast_means_weekly$forecast_mean - chla_observations$chla, na.rm = TRUE) 
bias_weekly

rmse_weekly <- round(sqrt(mean((forecast_means_weekly$forecast_mean - chla_observations$chla)^2, na.rm = TRUE)), 2)
rmse_weekly
```

**Q.XX** Compare the values of bias and RMSE for forecasts with weekly data assimilation to the values of bias and RMSE for forecasts with no data assimilation. According to these two measures, which series of forecasts is more accurate?

**Answer Q.XX**



Now, we will compare our series of 1-day-ahead forecasts with no data assimilation and weekly data assimilation to forecasts made with daily data assimilation.

Let's run the forecasts with daily data assimilation.

We will change our assimilation frequency to daily. 
```{r}
chla_assimilation_frequency_daily = 1
```

We will update our vector of chlorophyll-a data assimilation dates.
```{r}
chla_assimilation_dates_daily <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency_daily)]
```

Then, we will manipulate our lake data to create a `forecast_data_daily` dataframe, which is the data that will be provided to the model for forecasting.
```{r}
forecast_data_daily <- lake_data %>%
  select(datetime, chla) %>%
  mutate(datetime = as.Date(datetime)) %>%
  filter(datetime %in% forecast_dates) %>%
  mutate(chla = ifelse(datetime %in% chla_assimilation_dates_daily,chla,NA)) 
```

Next, we will create a data frame (`forecast_series_daily`) to hold the initial conditions and forecasts for each day in our forecast period. 
```{r}
forecast_series_daily <- tibble(date = rep(forecast_dates, each = n_members*2),
              chla = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Finally, we will populate our `forecast_series_daily` data frame with the initial conditions distribution for the very first day of the forecast period. 
```{r}
ic_distribution_daily <- ic_distribution #assign the first initial conditions distribution

temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              chla = ic_distribution_daily,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))

forecast_series_daily <- forecast_series_daily %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```

Finally, we run our series of forecasts! Here, we loop through days in our forecast period and generate 1-day-ahead predictions with our autoregressive model. 
```{r}
for(i in 2:length(forecast_dates)){
  
  #Generate forecast
  forecast_chla_daily = intercept + ar1 * (ic_distribution_daily - chla_mean) + chla_mean + process_distribution

  #Select current row of forecast_data to see if there is data to use for updating
  new_obs_daily <- forecast_data_daily$chla[i] #Observed chl-a

  #Update the initial condition
  ic_update_daily <- EnKF(forecast = forecast_chla_daily, new_observation = new_obs_daily, ic_sd = ic_sd)
  
  #Assign the updated initial condition to be used for the next day's forecast
  ic_distribution_daily <- ic_update_daily

  #Build temporary data frame to hold current initial condition and forecast
  temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               chla = c(forecast_chla_daily, ic_update_daily),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

  #Update rows of forecast series output data frame
  forecast_series_daily <- forecast_series_daily %>%
    rows_update(temp, by = c("date","ensemble_member","data_type"))
}
```

Let's plot our series of 1-day-ahead forecasts with weekly data assimilation.
```{r}
plot_many_forecasts(forecast_data = forecast_data_daily, forecast_series = forecast_series_daily)
```

**Q.XX** Describe how the mean value of the 1-day-ahead forecasts changes over time with daily data assimilation. 

**Answer Q.XX**



**Q.XX** Describe how the uncertainty distribution of the 1-day-ahead forecasts changes over time with daily data assimilation.

**Answer Q.XX**



Now, we will assess the performance of the series of forecasts with daily data assimilation.

To compare our forecasts to observations, we will first calculate the mean prediction for each day.
```{r}
forecast_means_daily <- forecast_series_daily %>%
  filter(data_type == "fc") %>%
  group_by(date) %>%
  summarize(forecast_mean = mean(chla, na.rm = TRUE))
```

Then, we will plot the forecasts again, this time with the observations that occurred during the forecast period.
```{r}
plot_many_forecasts_with_obs(forecast_data = forecast_data_daily, forecast_series = forecast_series_daily, chla_observations = chla_observations)
```

**Q.XX** Using the plot above, visually assess the forecasts and describe their accuracy. How well do they match observations? 

**Answer Q.XX**



Next, we will calculate the bias and RMSE of our forecasts. Remember, a smaller bias or RMSE indicates a more accurate forecast.
```{r}
bias_daily <- mean(forecast_means_daily$forecast_mean - chla_observations$chla, na.rm = TRUE) 
bias_daily

rmse_daily <- round(sqrt(mean((forecast_means_daily$forecast_mean - chla_observations$chla)^2, na.rm = TRUE)), 2)
rmse_daily
```

**Q.XX** Compare the values of bias and RMSE for forecasts with daily data assimilation to the values of bias and RMSE for forecasts with weekly and no data assimilation. According to these measures, which series of forecasts is the most accurate?

**Answer Q.XX**



**Q.XX** Fill in the blank: as the frequency of data assimilation increases, forecast accuracy ____________. *Choose from: increases, decreases, stays the same.*

**Answer Q.XX**



## 8. Make management decisions using forecasts generated with different frequencies of data assimilation.

NEED TO FIGURE OUT WHETHER TO RE-DO THIS (SEE PARTIAL DRAFT BELOW) OR GO WITH THE ONE FROM THE FIRST VERSION OF THE MODULE. GET THE CODE UPDATED FIRST AND THEN SEE WHAT SCENARIO WORKS BEST.

For this activity, you will act as the manager of a popular recreational beach for fishing and swimming on a large lake in the United States. Periodically, the lake experiences harmful algal blooms that may pose a threat to beach-goers due to algal toxin exposure. Your state agency has a water quality threshold of 10 ug/L for chlorophyll-a. If chlorophyll-a surpasses this threshold, the beach must be closed. If you choose to close the beach unnecessarily, many beach-goers will be very frustrated. But if you don't close the beach and chlorophyll-a levels surpass the water quality threshold, you are putting beach-goers at risk of exposure to algal toxins.

Your management agency is exploring the idea of developing a forecasting system for chlorophyll-a at the beach you manage. 

scenario data: do we close the beach on Sept 4?
```{r}
forecast_start_date <- "2018-10-04"

days_to_forecast = 7

forecast_dates <- seq.Date(from = as.Date(forecast_start_date), to = as.Date(forecast_start_date) + days_to_forecast, by = 'days')
```

make a forecast with last observation for data assimilation six days ago
set chla assimilation frequency
```{r}
chla_assimilation_frequency <- 8
```

```{r}
  chla_assimilation_dates <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(chla = ifelse(datetime %in% chla_assimilation_dates,chla,NA)) 
  
  curr_chla <- forecast_data$chla[1]
```

create data frames to hold initial conditions and forecasts
```{r}
ens <- tibble(date = rep(forecast_dates, each = n_members*2),
              ens = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Add OG initial conditions distribution to data frame
```{r}
ic_sd = 0.3
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              ens = ic_distribution,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))
ens <- ens %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```


for-loop for forecasting
Run forecast. Here, we loop through days into the future and generate predictions with our autoregressive model. Note we use the `rows_update()` function to replace NAs with forecasted chlorophyll-a and updated initial condition values each day.
```{r}
for(i in 2:length(forecast_dates)){
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}

#Select current row of forecast_data to see if there is data to use for updating
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- forecast_data$chla[i] #Observed chl-a

#Update the initial condition
x_update <- EnKF(x_corr, y, ic_sd)
ic_distribution <- c(x_update[,1])

#Build temporary data frame
temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               ens = c(x_corr[,1],x_update[,1]),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

#Update rows
ens <- ens %>%
  rows_update(temp, by = c("date","ensemble_member","data_type"))
}
fc1 <- ens
```

Plot output
```{r}
plot_scenario_forecasts(forecast_data, fc1)
```

And now with daily DA
make a forecast with last observation for data assimilation one day ago
set chla assimilation frequency
```{r}
chla_assimilation_frequency <- 1
```

```{r}
  chla_assimilation_dates <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(chla = ifelse(datetime %in% chla_assimilation_dates,chla,NA)) 
  
  curr_chla <- forecast_data$chla[1]
```

create data frames to hold initial conditions and forecasts
```{r}
ens <- tibble(date = rep(forecast_dates, each = n_members*2),
              ens = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Add OG initial conditions distribution to data frame
```{r}
ic_sd = 0.3
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              ens = ic_distribution,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))
ens <- ens %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```


for-loop for forecasting
Run forecast. Here, we loop through days into the future and generate predictions with our autoregressive model. Note we use the `rows_update()` function to replace NAs with forecasted chlorophyll-a and updated initial condition values each day.
```{r}
for(i in 2:length(forecast_dates)){
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}

#Select current row of forecast_data to see if there is data to use for updating
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- forecast_data$chla[i] #Observed chl-a

#Update the initial condition
x_update <- EnKF(x_corr, y, ic_sd)
ic_distribution <- c(x_update[,1])

#Build temporary data frame
temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               ens = c(x_corr[,1],x_update[,1]),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

#Update rows
ens <- ens %>%
  rows_update(temp, by = c("date","ensemble_member","data_type"))
}
fc2 <- ens
```

Plot output
```{r}
plot_scenario_forecasts(forecast_data, fc2)
```

A lot of question here for students to answer about why the forecasts look the way they do (the EnKF can't correct all the way to the observation!)

The big reveal
```{r}
plot_scenario_forecasts(forecast_data, fc1, show_final_obs = TRUE)
plot_scenario_forecasts(forecast_data, fc2, show_final_obs = TRUE)

```

Assess the forecasts - I bet the second set of forecasts has better RMSE, but you still got the wrong answer!

Assess forecast performance

For the low-frequency DA
```{r}
chla_observations <- lake_data %>%
  filter(datetime %in% forecast_dates)

forecast_means1 <- fc1 %>%
  filter(data_type == "fc") %>%
  group_by(date) %>%
  summarize(forecast_mean = mean(ens, na.rm = TRUE))

bias1 <- mean(forecast_means1$forecast_mean - chla_observations$chla, na.rm = TRUE) 
bias1

rmse1 <- round(sqrt(mean((forecast_means1$forecast_mean - chla_observations$chla)^2, na.rm = TRUE)), 2)
rmse1


```

For the high-frequency DA
```{r}
forecast_means2 <- fc2 %>%
  filter(data_type == "fc") %>%
  group_by(date) %>%
  summarize(forecast_mean = mean(ens, na.rm = TRUE))

bias2 <- mean(forecast_means2$forecast_mean - chla_observations$chla, na.rm = TRUE) 
bias2

rmse2 <- round(sqrt(mean((forecast_means2$forecast_mean - chla_observations$chla)^2, na.rm = TRUE)), 2)
rmse2
```


What are the other limitations in this forecasting system? What could be done to fix them?

## 9. Explore data assimilation for a different water quality variable.

Choose between temp, DO, and surface nitrogen. Alter the code below to read in the appropriate dataset:
1. water temperature: BARC_wtemp_celsius.csv
2. dissolved oxygen: BARC_dissolvedOxygen_milligramsPerLiter.csv
3. surface nitrogen: BARC_surfN_micromolesPerLiter.csv
```{r}
lake_data <- read_csv("./data/neon/BARC_chla_microgramsPerLiter.csv", show_col_types = FALSE) %>%
  rename(datetime = Date, chla = V1) %>%
  filter(cumsum(!is.na(chla)) > 0) %>%
  mutate(chla = ifelse(chla < 0, 0, chla))

head(lake_data)
```

Alter the code below to plot your new water quality variable rather than chl-a
```{r}
ggplot(data = lake_data, aes(x = datetime, y = chla))+
    geom_line(aes(color = "Chl-a"))+
    xlab("")+
    ylab(expression(paste("Chlorophyll-a (ug/L)")))+
    scale_color_manual(values = c("Chl-a" = "chartreuse4"), name = "")+
    theme_bw()
```

Fit an autoregressive model to your data. Alter the code below to fit a model to your new water quality variable.
```{r}
forecast_start_date <- "2020-09-25"

autocorrelation_data <- lake_data %>%
    filter(datetime < forecast_start_date) %>%
    mutate(chla = na.approx(chla, na.rm = F)) %>% 
    mutate(chla_lag = lag(chla)) %>% #EDIT THIS TO BE YOUR CHOSEN VARIABLE
    filter(complete.cases(.))

head(autocorrelation_data)

ar_model <- ar.ols(model_data$chla, order.max = 1, aic = FALSE,
                     intercept = TRUE, demean = TRUE)
```

Next, let's extract our model parameters and have a look at them.

First, $\beta_0$, the intercept:
```{r}
intercept = c(ar_model$x.intercept)
intercept
```

Next, $\beta_1$, the 1-day lag coefficient:
```{r}
ar1 = c(ar_model$ar)
ar1
```

Then, the mean of your chosen water quality variable:
```{r}
var_mean = c(ar_model$x.mean)
var_mean
```

Assess how well model fits data - make dataframe
```{r}
model_fit_plot_data <- tibble(date = model_data$datetime,
                              chla = model_data$chla, #EDIT THIS TO BE YOUR VARIABLE
                              model = mod)
```

Now, we can assess our model visually. We will plot the model predictions and observations.
```{r}
plot_mod_predictions(model_fit_plot_data, variable_name = "YOUR VARIABLE NAME HERE")
```

Calculate RMSE
```{r}
rmse <- round(sqrt(mean((mod - model_data$chla)^2, na.rm = TRUE)), 2)
rmse
```

Save residuals for process uncertainty
```{r}
residuals <- mod - model_data$chla
```

Calculate IC and process uncertainty

Set number of ensemble members
```{r}
n_members = 500
```

Read in high-frequency data
```{r}
high_frequency_data <- read_csv("./data/BARC_chla_microgramsPerLiter_highFrequency.csv", show_col_types = FALSE) %>%
  mutate(date = date(datetime),
         time = hms::as_hms(datetime)) %>%
  filter(date >= "2019-10-09" & date <= "2019-10-12")
```

Plot high-frequency data
```{r}
ggplot(data = high_frequency_data)+
  geom_line(aes(x = time, y = chla, group = date, color = as.factor(date)))+
  theme_bw()+
  labs(color = "Date")+
  xlab("Hour of day")+
  ylab("Chlorophyll-a (ug/L)")
```

Calculate standard deviation of variable each day
```{r}
ic_sd_dataframe <- high_frequency_data %>%
  group_by(date) %>%
  summarize(daily_sd_chla = sd(chla, na.rm = TRUE))
  
ic_sd <- mean(ic_sd_dataframe$daily_sd_chla, na.rm = TRUE)
ic_sd
```


Now, we can generate a distribution of initial conditions for our forecast using the current chlorophyll-a (`curr_chla`) and a standard deviation in units of ug/L calculated from high-frequency data from Lake Barco (`ic_sd`).

To do this, we will use the `rnorm()` function, which takes `n` draws from a normal distribution with a `mean` and `sd` specified as arguments to the function.
```{r}
curr_chla <- lake_data %>%
  filter(datetime == forecast_start_date) %>%
  pull(chla)

ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
```

Plot the distribution around your initial condition. This represents the **initial conditions uncertainty** of your forecast.
```{r}
plot_ic_dist(curr_chla, ic_distribution)
```

To calculate process uncertainty, we will define the standard deviation of the process uncertainty distribution, `sigma` as the standard deviation of the residuals. This is the uncertainty left over after we found the best parameters for fitting the model.

```{r}
sigma <- sd(residuals, na.rm = TRUE) # Process Uncertainty Noise Std Dev.; this is your sigma
```

Use `rnorm()` your process uncertainty distribution, using 0 as the mean and `sigma` as the standard deviation.
```{r}
process_distribution <- rnorm(n = n_members, mean = 0, sd = sigma)
```

Plot the process uncertainty distribution. We will use this distribution to account for uncertainty in our forecast.
```{r}
plot_process_dist(process_distribution)
```

Run forecasts with different frequencies of data assimilation and assess forecast performance: the goal is to figure out the optimal frequency of data collection to minimize RMSE over the forecast period.

set chla assimilation frequency
```{r}
chla_assimilation_frequency <- 1
```

```{r}
  chla_assimilation_dates <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(chla = ifelse(datetime %in% chla_assimilation_dates,chla,NA)) 
```

create data frames to hold initial conditions and forecasts
```{r}
ens <- tibble(date = rep(forecast_dates, each = n_members*2),
              ens = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Add OG initial conditions distribution to data frame
```{r}
ic_sd = 0.3
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              ens = ic_distribution,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))
ens <- ens %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```


for-loop for forecasting
Run forecast. Here, we loop through days into the future and generate predictions with our autoregressive model. Note we use the `rows_update()` function to replace NAs with forecasted chlorophyll-a and updated initial condition values each day.
```{r}
for(i in 2:length(forecast_dates)){
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}

#Select current row of forecast_data to see if there is data to use for updating
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- forecast_data$chla[i] #Observed chl-a

#Update the initial condition
x_update <- EnKF(x_corr, y, ic_sd)
ic_distribution <- c(x_update[,1])

#Build temporary data frame
temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               ens = c(x_corr[,1],x_update[,1]),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

#Update rows
ens <- ens %>%
  rows_update(temp, by = c("date","ensemble_member","data_type"))
}
```

Plot output
```{r}
plot_many_forecasts(forecast_data, ens)
```

Questions to assess which frequency of data assimilation is best for this variable and maybe compare that to chl-a results.