---
title: "Macrosystems EDDIE Module 7: Using Data to Improve Ecological Forecasts"
author: "Mary Lofton, Tadhg Moore, Quinn Thomas, Cayelan Carey"
date: "`r Sys.Date()`"
output:
  github_document: default
---

## Purpose of this R Markdown

This R Markdown contains code to reproduce the basic functionality of "Macrosystems EDDIE Module 7: Using Data to Improve Ecological Forecasts" outside of R Shiny. The code can be used by students to better understand what is happening "under the hood" of the Shiny app, which can be found at the following link:  
https://macrosystemseddie.shinyapps.io/module7/. 

Alternatively, students can complete this version of the module instead of the Shiny app version. 

## Summary

### Focal question for this module:   

**How can we use data to improve ecological forecasts?**

To be useful for management, ecological forecasts need to be both accurate enough for managers to be able to rely on them for decision-making and include a representation of forecast uncertainty, so managers can properly interpret the probability of future events. To improve forecast accuracy, we can update forecasts with observational data once they become available, a process known as **data assimilation.** Recent improvements in environmental sensor technology and an increase in the number of sensors deployed in ecosystems have resulted in an increase in the availability of data for assimilation to help develop and improve forecasts for natural resource management. In this module, you will develop an autoregressive model of primary productivity and use the model to generate forecasts. You will then explore how assimilating data at different temporal frequencies (e.g., daily, weekly) and with different levels of observation uncertainty affects forecast accuracy. 

## Learning Outcomes
1. Define data assimilation.    
2. Generate an ecological forecast for primary productivity.    
3. Describe how to assess ecological forecast accuracy.     
4. Describe how data assimilation affects forecast accuracy and uncertainty.    
5. Explain how updating models with data collected at different time scales (e.g., daily, weekly) and with different levels of associated uncertainty affects ecological forecasts.     

## Key Concepts

### What is data assimilation?

Data assimilation is the process of updating models with data. In ecological forecasting, data assimilation is the process of updating ecological forecasting models with new environmental data as they become available.

### How does the amount of uncertainty in model predictions and data affect the process of data assimilation?

The amount of uncertainty in model predictions and data determines how much we adjust our forecasts based on new observations. For example, if we observe a new data point and we have low observation uncertainty, our forecast starting conditions will be adjusted to closely correspond to the new observation. If we observe a new data point and we have high observation uncertainty, our forecast starting conditions will not be adjusted as much.

### How does the frequency of observations affect data assimilation?

More frequent observations allow us to update our forecast models more often, potentially improving forecast accuracy.

## Overview

In this module, we will generate one-day-ahead forecasts of lake chlorophyll-a. First, we will generate forecasts that do not assimilate any data. This will involve the following steps:  

#### Activity A
Objective 1. Read in and visualize chlorophyll-a data from Lake Barco, FL, USA.  
Objective 2. Explore autocorrelation of Lake Barco chlorophyll-a data.    
Objective 3. Fit an autoregressive forecast model.   
Objective 4. Generate a one-day-ahead forecast with uncertainty.

Next, we will explore the effect of **data assimilation** on forecast output.  

#### Activity B
Objective 5. Compare one-day-ahead forecasts generated with and without data assimilation. 
Objective 6. Compare one-day-ahead forecasts generated with data assimilation, using data with low vs. high observation uncertainty.
Objective 7. Compare a series of one-day-ahead forecasts with no data assimilation, weekly data assimilation, and daily data assimilation. 

Finally, you will be asked to apply what you have learned about how data collection frequency and observation uncertainty affect data assimilation to improve forecast accuracy.

#### Activity C
Objective 8. Made management decisions using forecasts generated with different frequencies of data assimilation.

There are a total of XX questions embedded throughout this module, many of which parallel (and in some cases are identical to) questions in the R Shiny app version of the module. Questions which are identical to those in the Shiny app will be indicated with **(Shiny)**, while questions unique to this RMarkdown will be indicated with **(Rmd)**. Note that question numbers will differ between the RMarkdown and the Shiny app, even if the question text is the same. Please see the module rubric for possible points per question and confirm with your instructor whether and how the module will be graded.  

## Think About It!

**Q.1 (Shiny)** What is meant by the term 'data assimilation' in the context of ecological forecasting?

**Answer Q.1**



**Q.2 (Shiny)** How do you think the process of integrating the most recently observed data into models can improve forecasts?

**Answer Q.2**


## Set-up

We will install and load some packages and functions that are needed to run the module code. 

If you do not currently have the packages below downloaded for RStudio, you will need to install them first using the `install.packages()` function (uncomment the lines and install the packages).

We will also load some custom functions that are stored in the `Rmd_functions.R` file using the `source()` function.

```{r, echo=FALSE, message = FALSE, warning=FALSE}
# install.packages("tidyverse")
# install.packages("lubridate")
# install.packages("zoo")
# install.packages("mvtnorm")
# install.packages("see")
library(tidyverse)
library(lubridate)
library(zoo)
library(mvtnorm)
library(see)

source("./Rmd_functions.R")
```

## 1. Read in and visualize data from Lake Barco, FL, USA

Lake Barco is one of the lake sites in the U.S. National Ecological Observatory Network (NEON). Please refer to https://www.neonscience.org/field-sites/barc to learn more about this site.

**Q.3 (Shiny)** Use the website linked above to fill out information about Lake Barco:

**Answer Q.3**

Four letter site identifier:  
Latitude:  
Longitude:  
Lake area (km2):  
Elevation (m):  

### Chlorophyll-a in lakes

Chlorophyll-a concentrations are an indicator of algal (phytoplankton) abundance and biomass in a lake. Phytoplankton are important primary producers at the base of the lake food web, and are therefore necessary for healthy lake ecosystem function. However, an overabundance of phytoplankton can lead to harmful blooms. 

Blooms compromise water quality via unsightly scums, clogging of filters at water treatment plants, release of noxious taste and odor compounds, and in some cases release of toxins that pose substantial risk to human and animal health. 

Forecasts of chlorophyll-a concentrations days to weeks into the future can give water managers important information about the likelihood of a bloom event. This permits pre-emptive management to prevent or mitigate water quality concerns caused by blooms.

**Q.4 Why might a forecast of lake chlorophyll-a concentration days to weeks into the future be a useful tool for water managers?**

**Answer Q.4**



Now we will read in and view lake chlorophyll-a data. 

We will rename the columns of our dataframe, and use the `cumsum()` function to filter out several rows with NA chlorophyll-a values at the beginning of our dataset. Here, the `cumsum()` function returns, at each row, the cumulative number of non-NA chl-a values up to that row. This allows us to filter out NA values at the beginning of the dataset, because as soon as the first non-NA chl-a value is observed, the `cumsum()` function will return a value greater than 0.

Finally, we will use the `mutate()` function to set any chl-a values that are less than 0 due to sensor error to 0, as negative chl-a values (representing negative phytoplankton) are not actually possible.
```{r}
lake_data <- read_csv("./data/neon/BARC_chla_microgramsPerLiter.csv", show_col_types = FALSE) %>%
  rename(datetime = Date, chla = V1) %>%
  filter(cumsum(!is.na(chla)) > 0) %>%
  mutate(chla = ifelse(chla < 0, 0, chla))

head(lake_data)
```

Plot a timeseries of chlorophyll-a observations at Lake Barco.
```{r}
ggplot(data = lake_data, aes(x = datetime, y = chla))+
    geom_line(aes(color = "Chl-a"))+
    xlab("")+
    ylab(expression(paste("Chlorophyll-a (ug/L)")))+
    scale_color_manual(values = c("Chl-a" = "chartreuse4"), name = "")+
    theme_bw()
```

**Q.5 Describe how chlorophyll-a changes over time in Lake Barco. Do you notice any patterns or trends?**

**Answer Q.5**

## 2. Explore autocorrelation of Lake Barco chlorophyll-a data.    

### What is autocorrelation?    

**Autocorrelation** is the correspondence between a value and previous values of that variable which have been recently observed. For example, mean daily air temperature over the course of a year exhibits autocorrelation, as today's mean daily air temperature is related to the mean daily air temperatures observed over the days and weeks prior to today. 

The **incredibly useful** thing about autocorrelation from a forecasting perspective is that it allows us to use *previous or current observations* of a variable to predict *future values* of that variable - excellent!

### What is a lag?  

A **lag** is a particular amount of time that has passed between when we observe a value we are using as an explanatory, or independent, variable, and when we observe a value that we are trying to predict. For example, if you use today's air temperature to predict tomorrow's air temperature, you are using a 1-day lag of air temperature to predict tomorrow's air temperature. 

You could also use a 2-day lag of air temperature (that would be the air temperature observed yesterday), or a 3-day lag, 4-day lag, and so on..... or some combination of all of those lags, to predict tomorrow's air temperature.

In general, stronger relationships among lags of a variable leads to higher **autocorrelation** in a timeseries of that variable.

**Q.6 Explain, in your own words, how autocorrelation in a variable can help forecasters make predictions of the future.** 

**Answer Q.6**

Let's explore lags and autocorrelation in chl-a data at Lake Barco.

First, we need to do some data wrangling. We will `filter()` our dataset to only include data that are observed prior to our forecast date, which is 2020-09-25. These are the data we will eventually use to fit our forecast model.

We will also linearly interpolate missing values in our chlorophyll-a data using the `na.approx()` function, and create a column of 1-day lagged values of chlorophyll-a using the `lag()` function. 

Finally, we will double-check that we have no missing values in our dataset by using `complete.cases()` to eliminate rows with NA values. This is important because we cannot have NA values when we fit our forecasting model to our data later on.
```{r}
forecast_start_date <- "2020-09-25"

autocorrelation_data <- lake_data %>%
    filter(datetime < forecast_start_date) %>%
    mutate(chla = na.approx(chla, na.rm = F)) %>% 
    mutate(chla_lag = lag(chla)) %>%
    filter(complete.cases(.))

head(autocorrelation_data)
```

Next, we will create an example plot to illustrate the concept of a **lagged variable**. To make it easier to see the 1-day lag in chlorophyll-a on the figure, we will only plot data from the last four months in 2018.
```{r}
plot_data <- autocorrelation_data %>%
  filter(datetime > "2018-09-01" & datetime < "2018-12-31")

plot_chla_lag(plot_data)
```

**Q.7 Describe what you observe on the timeseries figure above. How do the two lines plotted on the timeseries (chlorophyll and 1 day lag of chlorophyll) relate to each other?** 

**Answer Q.7**



To visualize the relationship between chlorophyll and a 1 day lag of chlorophyll in a different way, we will also plot these two timeseries on a scatterplot. The dashed diagonal line represents the 1:1 line. The closer the points fall to this line, the stronger of the linear relationship between the independent variable (x axis) and the dependent variable (y axis).

Note that now, we are plotting the complete model fitting dataset (2017-10-21 to 2020-09-25).
```{r}
ggplot(data = autocorrelation_data, aes(x = chla_lag, y = chla))+
  geom_point()+
  xlab(expression(paste("1 day lag of chlorophyll-a (",mu,g,~L^-1,")")))+
  ylab(expression(paste("chlorophyll-a (",mu,g,~L^-1,")")))+
  geom_abline(slope = 1, intercept = 0, linetype = 2)+
  theme_bw()
```

**Q.8 Describe what you observe on the scatterplot figure above. Do you think the Lake Barco chlorophyll-a data exhibit autocorrelation? Why or why not?** 

**Answer Q.8**

 

In addition to visualizing autocorrelation, we can also calculate it. The autocorrelation between chlorophyll-a ($Chla$) and a 1-day lag of chlorophyll-a ($ChlaLag$) is represented by the following equation:

$$Autocorrelation = \frac {\sum_{t = 2}^{T} (
Chla - \overline{Chla}) * (
ChlaLag - \overline{Chla})}{\sum_{t = 1}^{T} (
Chla - \overline{Chla})^2}$$

where $T$ is the timeseries of observations in the timeseries and $t$ represents which observation in that timeseries we are starting with (either the 1st or 2nd observation). Recall that the capital sigma $(\sum)$ indicates a sum and the overline $(\overline{Chla})$ indicates the mean.

The closer the autocorrelation is to 1, the stronger the autocorrelation between the variable and its lag.

We can calculate autocorrelation in code. Note that in the following calculation, the `[-1]` eliminates the first element of `autocorrelation_data$chla` or `autocorrelation_data$chla_lag` vectors, following the $t=2$ specification for the $\sum_{t = 2}^{T}$ function in the numerator of the autocorrelation equation above.
```{r}
autocorrelation_lag1 = round(sum((autocorrelation_data$chla[-1] - mean(autocorrelation_data$chla[-1]))*(autocorrelation_data$chla_lag[-1] - mean(autocorrelation_data$chla[-1])))/sum((autocorrelation_data$chla - mean(autocorrelation_data$chla))^2),3)

autocorrelation_lag1
```

**Q.9 Interpret the value of `autocorrelation_lag1`; does this value indicate low or high autocorrelation between chlorophyll-a and a 1-day lag of chlorophyll-a?** 

**Answer Q.9**


Next, we can calculate and plot the autocorrelation values for many different lags of our chlorophyll-a data. Rather than doing this calculation step-by-step, we can use the `acf()` function to calculate the autocorrelation for many lags, and then plot them below.
```{r}
acf_list <- acf(autocorrelation_data$chla, plot = FALSE)

acf_plot_data <- tibble(Lag = acf_list$lag,
                        ACF = round(acf_list$acf, 2))

ggplot(data = acf_plot_data, aes(x = Lag, y = ACF))+
  geom_bar(stat = "identity")+
  xlab("Lag in days")+
  ylab("Autocorrelation")+
  theme_bw()
```

**Q.10 Describe how autocorrelation changes as the lag in days increases. Why do you think this pattern occurs?** 

**Answer Q.10**



**Q.11 Imagine you are asked to develop a forecasting model that uses lagged values of chlorophyll-a to predict future chlorophyll-a. Examining the autocorrelation plot above, how many lags of chlorophyll-a would you include in your forecasting model? Provide your answer in days (e.g., I would include up to a 3-day lag) and explain your reasoning.**

**Answer Q. 11**
 

As you may have discovered while answering Q.11, it can be difficult to decide exactly how many lags to include in a forecasting model. Fortunately, forecasters have developed tools to help make this decision. One such tool is the **partial autocorrelation function**, or **PACF**. This function calculates the autocorrelation of a particular lag *while removing* the effects of indirect correlations with other lags. 

To explain another way: the **autocorrelation** of chlorophyll-a and the 7-day lag of chlorophyll-a is affected by the autocorrelation of chlorophyll-a with the 1-day lag, the 2-day lag, the 3-day lag, and so on, as well as the relationship of the 7-day lag to the 1-day lag, the 2-day lag, the 3-day lag, and so on.

The PACF avoids this problem. You can think of it as only measuring the effect of one particular set of lagged values (e.g., the 5-day lagged values), while accounting for (and thereby removing the influence of) all other lags.

To calculate the PACF, we can use the same `acf()` function, while adding the argument `type = c("partial")` to indicate that we'd like to calculate the partial autocorrelation function. 
```{r}
pacf_list <- acf(autocorrelation_data$chla, type = c("partial"), plot = FALSE)

pacf_plot_data <- tibble(Lag = pacf_list$lag,
                         Partial_ACF = round(pacf_list$acf, 2))
head(pacf_plot_data)
```
Now, we can plot the PACF.
```{r}
ggplot(data = pacf_plot_data, aes(x = Lag, y = Partial_ACF))+
  geom_bar(stat = "identity")+
  xlab("Lag in days")+
  ylab("Partial autocorrelation")+
  theme_bw()
```

**Q.12 Examine the PACF plot. Which lag contributes the most to autocorrelation in the Lake Barco chlorophyll-a data? Explain how you know.**

**Answer Q. 11**



**Q.13 Once again, imagine you are asked to develop a forecasting model that uses lagged values of chlorophyll-a to predict future chlorophyll-a. Examining the PACF plot above, how many lags of chlorophyll-a would you include in your forecasting model? Provide your answer in days (e.g., I would include up to a 3-day lag) and explain your reasoning.**

**Answer Q. 13**




**Q.14 Did the number of lags you chose to include in your forecasting model change from Q.11 to Q.13? Why or why not?**

**Answer Q. 14**




## 3. Fit an autoregressive forecast model.   

### What is an autoregressive model?  

An **autoregressive model** uses past and/or current values of a variable to predict future values. In our case, we are interested in using past and current values of lake chlorophyll-a to predict future chlorophyll-a.

Today, we will fit a simple form of an autoregressive, or AR model, which uses yesterday's chlorophyll-a observation (so, a 1-day lag) to predict today's observation. This model can be written as:

$$Chla_{t} = \beta_0 + \beta_1 * (Chla_{t-1} - \overline{Chla}) + \overline{Chla}$$
where $Chla$ is our timeseries of chlorophyll-a data, $\beta_0$ is the intercept parameter, $\beta_1$ is the coefficient on the 1-day lag of chlorophyll-a, and $\overline{Chla}$ is the mean of the chlorophyll-a timeseries.

Let's fit this model to our data! 
```{r}
model_data <- autocorrelation_data 
```

To fit our model, we will use the `ar.ols()` function, which fits an autoregressive time series model to data by ordinary least squares. 

While it's possible that including additional lags besides a 1-day lag might improve our predictions, for today, we will keep it simple and just use a 1-day lag. We will specify this by adding the `order.max = 1` argument to our function. 

In addition, we will specify:

1. `aic = FALSE` because we know we only want to use the first lag, we don't need to use the AIC, or Akaike Information Criterion, to help us choose how many lags to include
2. `intercept = TRUE` we do want to fit an intercept term
3. `demean = TRUE` we do want to subtract the mean
```{r}
ar_model <- ar.ols(model_data$chla, order.max = 1, aic = FALSE,
                     intercept = TRUE, demean = TRUE)
```

Next, let's extract our model parameters and have a look at them.

First, $\beta_0$, the intercept:
```{r}
intercept = c(ar_model$x.intercept)
intercept
```

Next, $\beta_1$, the 1-day lag coefficient:
```{r}
ar1 = c(ar_model$ar)
ar1
```

Then, the mean of chlorophyll-a:
```{r}
chla_mean = c(ar_model$x.mean)
chla_mean
```

**Q.15 Explain, in your own words, how the autoregressive model you have just fitted predicts chlorophyll-a.**


**Answer Q. 15**


### How can we assess model fit?

Before we use this model for forecasting, it is a good idea to see how well it fits our data. We will use three methods for doing this:

1. Visual observation of model predictions vs. observations. This is a simple but effective method. The closer your model predictions fall to your observations, the better the model fit.
2. **Bias**: Bias is the mean difference between model predictions and observations. The smaller the absolute value of the bias, the better your model fit.
3. **Root mean square error (RMSE)**: RMSE is the mean sum of squared errors (differences between predictions and observations), and can be calculated as:

$$RMSE = \sqrt{\frac{\sum_{i=1}^{N}(Predicted_i - Observed_i)^2}{N}}$$
The closer the RMSE is to 0, the better your model fit.

First, let's use our fitted model to generate predictions.
```{r}
mod <- intercept + ar1 * (model_data$chla - chla_mean) + chla_mean
```

Next, we will creat a data frame for plotting and exponentiate the model predictions using `exp()`. Exponentiation reverses the log-transformation and is needed before we can compare our predictions to data.
```{r}
model_fit_plot_data <- tibble(date = model_data$datetime,
                              chla = model_data$chla,
                              model = mod)
```

Now, we can assess our model visually. We will plot the model predictions and observations.
```{r}
plot_mod_predictions(model_fit_plot_data, variable_name = "Chlorophyll-a (ug/L)")
```

**Q.16 Use the plot above to assess the model fit to data. How well do the predictions match the observations?**


**Answer Q. 16**



Next, we will calculate bias. The units of bias are the same as the predicted variable (in our case, $\mu g L^{-1}$).
```{r}
bias <- mean(mod - model_data$chla, na.rm = TRUE) 
bias
```
**Q.17 Use the calculated bias to assess the model fit to data. How good is the model fit? Explain your reasoning.**


**Answer Q. 17**



Finally, we will calculate RMSE. The units of RMSE are also the same as the predicted variable.
```{r}
rmse <- round(sqrt(mean((mod - model_data$chla)^2, na.rm = TRUE)), 2)
rmse
```
**Q.18 Use the calculated RMSE to assess the model fit to data. How good is the model fit? Explain your reasoning.**

**Answer Q. 18**



We will also save the **residuals** of our model, which are the differences between model predictions and observations. We will need these values later on to account for **process uncertainty**, or uncertainty due to the structure of our model, in our forecasts.
```{r}
residuals <- mod - model_data$chla
```


## 4. Generate a one-day-ahead forecast with uncertainty.

Finally, we are ready to generate a forecast with our fitted model! 

### A note on shifting from model fitting to forecasting
So far, we have fit our chlorophyll-a model using yesterday's chlorophyll-a to predict today's chlorophyll-a. 
 
Now, to forecast, we will need to make a subtle but important change in the way we write our model, to show that instead of predicting today's chlorophyll-a, we are now forecasting tomorrow's chlorophyll-a:

$$Chla_{t+1} = \beta_0 + \beta_1 * (Chla_{t1} - \overline{Chla}) + \overline{Chla}$$
Note the change in the subscripts of the Chla variables from t-1 to t and t to t+1!!

To generate a forecast using our model, we use today's observation to make a prediction for tomorrow. But before we can do that, we need to calculate the uncertainty associated with our forecast.

### What is ecological forecast uncertainty? 

Forecast uncertainty is the range of possible alternate future conditions predicted by a model. We generate multiple different predictions of the future because the future is inherently unknown.  

### Where does ecological forecast uncertainty come from?

Uncertainty comes from natural variability in the environment, imperfect representation of an ecological system in a model, and error when measuring the system. When generating a forecast, uncertainty can come from the structure of the model used, the initial conditions of the model, the parameters of the model, and the data used to drive the model, among other sources.

### Why is uncertainty important to quantify for an ecological forecast? 

Knowing the uncertainty in a forecast allows forecast users to make informed decisions based on the range of forecasted outcomes and prepare accordingly.

### What is an ensemble forecast?
One way of accounting for uncertainty in forecasts is through an **ensemble forecast**. Ensemble forecasts are generated by running a model many times with different conditions. In our case, we will run our autoregressive model many times using different initial conditions and adding slightly different random noise (W) values to account for initial conditions and process uncertainty in the forecast. All the model runs together are referred to as the **ensemble**. Each individual model run is referred to as an **ensemble member**. Forecasters typically generate tens to hundreds of ensemble members to build uncertainty into their forecasts.  

We will set the number of ensemble members we would like to have in our ensemble forecast.
```{r}
n_members = 500
```


**Q.XX** Explain, in your own words, what forecast uncertainty is and why it is important to account for uncertainty in forecasts.

**Answer Q.XX**



### Sources of forecast uncertainty

Today, we will be accounting for two sources of forecast uncertainty: **initial conditions uncertainty** and **process uncertainty**.

#### What are forecast **initial conditions**?

**Initial conditions** are the starting conditions of your model when you generate a forecast. 

#### What is **initial conditions uncertainty**?

**Initial conditions uncertainty** refers to uncertainty arising because the current conditions in an ecosystem - in our case, lake chlorophyll-a - are not precisely known.

Even though we have measurements of chlorophyll-a from our lake, we know that chlorophyll-a varies throughout the day so this measurement might not capture exactly the chlorophyll-a in our lake at this time. Additionally, there may be observation error in our chlorophyll-a measurements.

To account for initial conditions uncertainty we can generate a distribution around the initial condition of chlorophyll-a and then run our model with slightly different initial conditions.


**Q.19** What data from Lake Barco are needed to provide the initial condition for your forecast model? 

**Answer Q.19**



So far, we have been working with daily mean chlorophyll-a values from Lake Barco to fit our model and generate a deterministic forecast.

Now, we will use some high-frequency (5-minute) chlorophyll-a data from our lake to estimate initial conditions uncertainty. For ease of visualization, we will only look at data from 2019-10-09 to 2019-10-12.
```{r}
high_frequency_data <- read_csv("./data/BARC_chla_microgramsPerLiter_highFrequency.csv", show_col_types = FALSE) %>%
  mutate(date = date(datetime),
         time = hms::as_hms(datetime)) %>%
  filter(date >= "2019-10-09" & date <= "2019-10-12")
```
We can look at variability in this 5-minute data over the course of a day to get a visual understanding of the daily variability in chlorophyll-a. Each colored line in the plot below represents a different day of chl-a data from midnight to midnight. 
```{r}
ggplot(data = high_frequency_data)+
  geom_line(aes(x = time, y = chla, group = date, color = as.factor(date)))+
  theme_bw()+
  labs(color = "Date")+
  xlab("Hour of day")+
  ylab("Chlorophyll-a (ug/L)")
```

**Q.20** Examine the plot of high-frequency chlorophyll-a data. How variable is chlorophyll-a over the course of a day? 

**Answer Q.20**



**Q.21** Recall that we are using the daily mean of chlorophyll-a as the initial condition for our model. Given the daily variability that you see in the high-frequency chlorophyll-a data, do you think that using a daily mean is a good representation of daily chlorophyll-a in Lake Barco? Explain your reasoning.

**Answer Q.21**




Next, we will calculate the mean daily standard deviation of chl-a measurements (`ic_sd`), which we will use to estimate uncertainty in our initial conditions. 
```{r}
ic_sd_dataframe <- high_frequency_data %>%
  group_by(date) %>%
  summarize(daily_sd_chla = sd(chla, na.rm = TRUE))
  
ic_sd <- mean(ic_sd_dataframe$daily_sd_chla, na.rm = TRUE)
ic_sd
```


Now, we can generate a distribution of initial conditions for our forecast using the current chlorophyll-a (`curr_chla`) and a standard deviation in units of ug/L calculated from high-frequency data from Lake Barco (`ic_sd`).

To do this, we will use the `rnorm()` function, which takes `n` draws from a normal distribution with a `mean` and `sd` specified as arguments to the function.
```{r}
curr_chla <- lake_data %>%
  filter(datetime == forecast_start_date) %>%
  pull(chla)

ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
```

Plot the distribution around your initial condition. This represents the **initial conditions uncertainty** of your forecast.
```{r}
plot_ic_dist(curr_chla, ic_distribution)
```

#### What is **process uncertainty** in an ecological forecast?

Process uncertainty is uncertainty caused by our inability to model all processes as observed in the real world.

Our 'simple' chlorophyll-a model uses today's chlorophyll-a to forecast tomorrow's chlorophyll-a. For example:

$$Chla_{t+1} = \beta_0 + \beta_1 * (Chla_{t1} - \overline{Chla}) + \overline{Chla}$$ 
But we know that chlorophyll-a can be affected by other processes as well (such as water temperature and the amount of available light and nutrients) and that our model has simplified or ignored these. To account for the uncertainty these simplifications introduce, we can add in process noise (W) at each time step. In this model, chlorophyll-a tomorrow is a function of today's chlorophyll-a plus some noise (W):

$$Chla_{t+1} = \beta_0 + \beta_1 * (Chla_{t1} - \overline{Chla}) + \overline{Chla} + W$$
where process noise is equal to a random number drawn from a normal distribution with a mean of zero and a standard deviation ($\sigma$).

$$W \sim {\mathrm Norm}(0, \sigma)$$

To account for process uncertainty, we can run the model multiple times with random noise added to each model run. More noise is associated with higher process uncertainty, and vice versa. But how much random noise should we add?

To calculate process uncertainty, we will define the standard deviation of the process uncertainty distribution, `sigma` as the standard deviation of the residuals. This is the uncertainty left over after we found the best parameters for fitting the model.

```{r}
sigma <- sd(residuals, na.rm = TRUE) # Process Uncertainty Noise Std Dev.; this is your sigma
```

Use `rnorm()` your process uncertainty distribution, using 0 as the mean and `sigma` as the standard deviation.
```{r}
process_distribution <- rnorm(n = n_members, mean = 0, sd = sigma)
```

Plot the process uncertainty distribution. We will use this distribution to account for uncertainty in our forecast.
```{r}
plot_process_dist(process_distribution)
```

Finally, we are ready to use our autoregressive model to generate a one-day-ahead forecast with uncertainty. Notice that we are using our initial condition and process uncertainty distributions to account for uncertainty in our forecast.
```{r}
forecast_chla = intercept + ar1 * (ic_distribution - chla_mean) + chla_mean + process_distribution
```

Let's take a look at our forecast for tomorrow with uncertainty!
```{r}
plot_fc_dist(forecast_chla)
```


To prepare you for our next activity, let's visualize this forecast in a different way, using a customized plotting function. We will use plots very similar to this one to help explain the process of data assimilation later on.

First we will define some arguments for the function:
1. `start_date` date forecast is generated
2. `forecast_date` date being forecasted
```{r}
start_date <- "2020-09-25" 
forecast_date <- "2020-09-26"
```

Plot the forecast.
```{r}
plot_fc_1day(curr_chla, start_date, forecast_date, ic_distribution, forecast_chla, n_members)
```

**Q.XX** What is the forecasted chlorophyll-a concentration for Sept. 26, 2020? 

*Hint: Remember, because forecasts are uncertain, there is not one single correct value for forecasted chlorophyll-a.*

**Answer Q.XX**



**Q.XX** What is the relationship between the observed chlorophyll-a for Sept. 25, 2020, and the initial condition distribution (shown in blue)?

**Answer Q.XX**



**Q.XX** Each one of the gray lines in the figure above represents an ensemble member. Explain what this means in your own words, with specific reference to the autoregressive model we are using for forecasting in this exercise.

**Answer Q.XX**


To learn more about forecast uncertainty, you can explore Macrosystems EDDIE Module 6: Understanding Uncertainty in Ecological Forecasts, which is available both as an [R Shiny app](https://macrosystemseddie.shinyapps.io/module6/) and as an [RMarkdown](https://github.com/MacrosystemsEDDIE/module6_R).

## Activity B

## 5. Compare one-day-ahead forecasts generated with and without data assimilation.

With data

We are going to make predictions.
```{r}
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}
```

data for the specific "day" that we are forecasting
```{r}
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- 7.5 #Observed chl-a
```


Update the forecast using the new data
```{r}
x_update <- EnKF(x_corr, y, ic_sd)
```

Data wrangling to bind it all together for plotting
HOW BEST TO DO THIS SO FUNCTION ARGUMENTS ARE TRACTABLE AND THERE ISN'T TOO MUCH WRANGLING CODE?
```{r}
chla_obs <- c(curr_chla, 7.5)
ic_update = c(x_update[,1])
plot_fc_1day(curr_chla, start_date, forecast_date, ic_distribution, forecast_chla, n_members)
plot_fc_update(chla_obs, start_date, forecast_date, ic_distribution, ic_update, forecast_chla, n_members)
```

Make predictions again.
```{r}
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_update[m] - chla_mean) + chla_mean + process_distribution[m] 
}
```

Plot again.
```{r}
second_forecast = c(x_corr[,1])
forecast_dates = c("2020-09-26","2020-09-27")
plot_second_forecast(chla_obs, start_date, forecast_dates, ic_distribution, ic_update, forecast_chla, second_forecast, n_members)
```

But what if there is no observation to use for updating?
```{r}
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- NA #No observed chl-a
```

Let's see what the EnKF does
```{r}
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}

x_update <- EnKF(x_corr, y, ic_sd)
```

Plot the new initial condition
```{r}
chla_obs <- c(curr_chla, NA)
ic_update = c(x_update[,1])
plot_fc_1day(curr_chla, start_date, forecast_date, ic_distribution, forecast_chla, n_members)
plot_fc_update(chla_obs, start_date, forecast_date, ic_distribution, ic_update, forecast_chla, n_members)
```

Make predictions again.
```{r}
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_update[m] - chla_mean) + chla_mean + process_distribution[m] 
}
```

Plot again.
```{r}
second_forecast = c(x_corr[,1])
forecast_dates = c("2020-09-26","2020-09-27")
plot_second_forecast(chla_obs, start_date, forecast_dates, ic_distribution, ic_update, forecast_chla, second_forecast, n_members)
```

## 6. Compare one-day-ahead forecasts generated with data assimilation, using data with low vs. high observation uncertainty.

With low observation uncertainty
```{r}
ic_sd = 0.1
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
plot_ic_dist(curr_chla, ic_distribution)
```


We are going to make predictions.
```{r}
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}
forecast_chla <- c(x_corr[,1])
```

data for the specific "day" that we are forecasting
```{r}
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- 7.5 #Observed chl-a
```


Update the forecast using the new data
```{r}
x_update <- EnKF(x_corr, y, ic_sd)
```

Data wrangling to bind it all together for plotting
HOW BEST TO DO THIS SO FUNCTION ARGUMENTS ARE TRACTABLE AND THERE ISN'T TOO MUCH WRANGLING CODE?
```{r}
chla_obs <- c(curr_chla, 7.5)
ic_update = c(x_update[,1])
plot_fc_1day(curr_chla, start_date, forecast_date, ic_distribution, forecast_chla, n_members)
plot_fc_update(chla_obs, start_date, forecast_date, ic_distribution, ic_update, forecast_chla, n_members)
```

Make predictions again.
```{r}
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_update[m] - chla_mean) + chla_mean + process_distribution[m] 
}
```

Plot again.
```{r}
second_forecast = c(x_corr[,1])
forecast_dates = c("2020-09-26","2020-09-27")
plot_second_forecast(chla_obs, start_date, forecast_dates, ic_distribution, ic_update, forecast_chla, second_forecast, n_members)
```

With high observation uncertainty
```{r}
ic_sd = 0.5
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
plot_ic_dist(curr_chla, ic_distribution)
```


We are going to make predictions.
```{r}
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}
forecast_chla <- c(x_corr[,1])
```

data for the specific "day" that we are forecasting
```{r}
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- 7.5 #Observed chl-a
```


Update the forecast using the new data
```{r}
x_update <- EnKF(x_corr, y, ic_sd)
```

Data wrangling to bind it all together for plotting
HOW BEST TO DO THIS SO FUNCTION ARGUMENTS ARE TRACTABLE AND THERE ISN'T TOO MUCH WRANGLING CODE?
```{r}
chla_obs <- c(curr_chla, 7.5)
ic_update = c(x_update[,1])
plot_fc_1day(curr_chla, start_date, forecast_date, ic_distribution, forecast_chla, n_members)
plot_fc_update(chla_obs, start_date, forecast_date, ic_distribution, ic_update, forecast_chla, n_members)
```

Make predictions again.
```{r}
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_update[m] - chla_mean) + chla_mean + process_distribution[m] 
}
```

Plot again.
```{r}
second_forecast = c(x_corr[,1])
forecast_dates = c("2020-09-26","2020-09-27")
plot_second_forecast(chla_obs, start_date, forecast_dates, ic_distribution, ic_update, forecast_chla, second_forecast, n_members)
```

## 7. Compare a series of one-day-ahead forecasts with no data assimilation, weekly data assimilation, and daily data assimilation. 

To do this in code, we will use a **for-loop**.

#### What is a for-loop?

A **for-loop** runs a section of code repeatedly. The number of times the for-loop runs is specified by the coder, either by specifying the number of times the code should be run before the for-loop stops. For example, below we write a for-loop that prints "Hello World!" eight times.
```{r}
for(i in 1:8){
  print("Hello World!")
}
```
**Notice:**      
1. We specify the number of times the for-loop should run with the code `for(i in 1:8)`. We will explain what the `i` refers to when we discuss indexing below.  
2. The code that is repeatedly run is contained in brackets `{}`.

#### What is indexing in a for-loop?

Within a for-loop, **indexing** allows you to refer to a particular iteration, or individual code run, of the loop. This can be useful if you want to, for example, perform a particular calculation on every row of a data frame. In R, `i` is commonly used for indexing in for-loops. Below we write a for-loop that prints the numbers 1 to 8 using indexing.
```{r}
for(i in 1:8){
  print(i)
}
```
#### How is indexing in a for-loop useful for ecological forecasting?
  
Often, we want to run a forecast model repeatedly to make predictions for multiple days into the future. For-loops can be a useful way to accomplish this, *particularly* if each day's prediction depends on the previous day.  
  
Let's pretend we have a very simple forecast model, where tomorrow's chlorophyll-a is equal to today's chlorophyll-a + 1 microgram per liter. If we wanted to generate a 7-day prediction of chlorophyll-a using this model, we could write a for-loop to do so.  
  
First, we set our initial observed chlorophyll-a.

```{r}
starting_chla <- 11.4 #micrograms per liter
```

Then, we create an empty vector in which we will store our starting chlorophyll-a as well as our predicted chlorophyll-a for the next seven days (so the total length of the vector = 8 days).

```{r}
chla <- rep(NA, 8)
```

Next, we set the first element of our empty vector to be the starting chlorophyll-a.

```{r}
chla[1] <- starting_chla
chla
```

Finally, we run a for-loop to generate 7 days of chlorophyll-a predictions, which will be stored in the `chla` vector. **Note** that the for-loop starts at the 2nd iteration (`for(i in 2:8)`) because we already know today's chlorophyll-a, so we are starting with tomorrow's prediction.

```{r}
for(i in 2:8){
  chla[i] = chla[i-1] + 1 #micrograms per liter
  print(chla[i])
}
```
  
**Q.XX (Rmd)** Can you alter the code below to generate a **10-day** prediction of chlorophyll-a rather than a 7-day prediction? What is the predicted chlorophyll-a on the 10th day?  
  
**Answer Q.XX** Edit the code block to provide your answer.
```{r}
starting_chla <- 11.4 #degrees C

chla <- rep(NA, 8)

chla[1] <- starting_chla
chla

for(i in 2:8){
  chla[i] = chla[i-1] + 1 #micrograms per liter
  print(chla[i])
}
```
  
Of course, this is probably not a very good model for predicting chlorophyll-a, because it would lead to chlorophyll-a increasing infinitely into the future! Next, we will use the concept of a for-loop to make a forecast of chlorophyll-a using the autoregressive model you fit above.

First, we will specify how many days we would like to forecast
```{r}
days_to_forecast = 10
```

Then we will create a date vector of our forecast start dates, based on how many days we would like to forecast.
```{r}
forecast_dates <- seq.Date(from = as.Date(forecast_start_date), to = as.Date(forecast_start_date) + days_to_forecast, by = 'days')

```

Next, we need to specify how often we want the forecast model to assimilate data. For this first series of forecasts, we want to see what happens when no data is assimilated during the forecast period (which is 10 days). So, we will set the `chla_assimilation_frequency` to 11 days, ensuring that no data will be assimilated during the 10-day forecast period.
```{r}
chla_assimilation_frequency = 11
```

Just before we run the forecast, we need to format our lake data to play nicely with our forecasting function. First, we will create a vector (`chla_assimilation_dates`) that we will use as an index to be sure that we only provide the model with the chlorophyll-a data that we want to assimilate. In this case, only the observation on the first day of the forecast period will be provided as the initial condition for the forecast. Then, we will manipulate our lake data to create a `forecast_data` dataframe, which is the data that will be provided to the model for forecasting.
```{r}
  chla_assimilation_dates <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(chla = ifelse(datetime %in% chla_assimilation_dates,chla,NA)) 
```

create data frames to hold initial conditions and forecasts
```{r}
ens <- tibble(date = rep(forecast_dates, each = n_members*2),
              ens = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Add OG initial conditions distribution to data frame
```{r}
ic_sd = 0.3
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              ens = ic_distribution,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))
ens <- ens %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```


for-loop for forecasting
Run forecast. Here, we loop through days into the future and generate predictions with our autoregressive model. Note we use the `rows_update()` function to replace NAs with forecasted chlorophyll-a and updated initial condition values each day.
```{r}
for(i in 2:length(forecast_dates)){
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}

#Select current row of forecast_data to see if there is data to use for updating
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- forecast_data$chla[i] #Observed chl-a

#Update the initial condition
x_update <- EnKF(x_corr, y, ic_sd)
ic_distribution <- c(x_update[,1])

#Build temporary data frame
temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               ens = c(x_corr[,1],x_update[,1]),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

#Update rows
ens <- ens %>%
  rows_update(temp, by = c("date","ensemble_member","data_type"))
}
```

Plot output
```{r}
plot_many_forecasts(forecast_data, ens)
```

Assess forecast performance

Calculate mean prediction for each day
```{r}
forecast_means <- ens %>%
  filter(data_type == "fc") %>%
  group_by(date) %>%
  summarize(forecast_mean = mean(ens, na.rm = TRUE))

chla_observations <- lake_data %>%
  filter(datetime %in% forecast_dates)
```

Calculate bias and RMSE
```{r}
bias <- mean(forecast_means$forecast_mean - chla_observations$chla, na.rm = TRUE) 
bias

rmse <- round(sqrt(mean((forecast_means$forecast_mean - chla_observations$chla)^2, na.rm = TRUE)), 2)
rmse
```


Do again for weekly

set chla assimilation frequency
```{r}
chla_assimilation_frequency <- 7
```

```{r}
  chla_assimilation_dates <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(chla = ifelse(datetime %in% chla_assimilation_dates,chla,NA)) 
```

create data frames to hold initial conditions and forecasts
```{r}
ens <- tibble(date = rep(forecast_dates, each = n_members*2),
              ens = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Add OG initial conditions distribution to data frame
```{r}
ic_sd = 0.3
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              ens = ic_distribution,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))
ens <- ens %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```


for-loop for forecasting
Run forecast. Here, we loop through days into the future and generate predictions with our autoregressive model. Note we use the `rows_update()` function to replace NAs with forecasted chlorophyll-a and updated initial condition values each day.
```{r}
for(i in 2:length(forecast_dates)){
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}

#Select current row of forecast_data to see if there is data to use for updating
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- forecast_data$chla[i] #Observed chl-a

#Update the initial condition
x_update <- EnKF(x_corr, y, ic_sd)
ic_distribution <- c(x_update[,1])

#Build temporary data frame
temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               ens = c(x_corr[,1],x_update[,1]),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

#Update rows
ens <- ens %>%
  rows_update(temp, by = c("date","ensemble_member","data_type"))
}
```

Plot output
```{r}
plot_many_forecasts(forecast_data, ens)
```

Assess forecast performance

Calculate mean prediction for each day
```{r}
forecast_means <- ens %>%
  filter(data_type == "fc") %>%
  group_by(date) %>%
  summarize(forecast_mean = mean(ens, na.rm = TRUE))

chla_observations <- lake_data %>%
  filter(datetime %in% forecast_dates)
```

Calculate bias and RMSE
```{r}
bias <- mean(forecast_means$forecast_mean - chla_observations$chla, na.rm = TRUE) 
bias

rmse <- round(sqrt(mean((forecast_means$forecast_mean - chla_observations$chla)^2, na.rm = TRUE)), 2)
rmse
```


Do again for daily
set chla assimilation frequency
```{r}
chla_assimilation_frequency <- 1
```

```{r}
  chla_assimilation_dates <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(chla = ifelse(datetime %in% chla_assimilation_dates,chla,NA)) 
```

create data frames to hold initial conditions and forecasts
```{r}
ens <- tibble(date = rep(forecast_dates, each = n_members*2),
              ens = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Add OG initial conditions distribution to data frame
```{r}
ic_sd = 0.3
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              ens = ic_distribution,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))
ens <- ens %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```


for-loop for forecasting
Run forecast. Here, we loop through days into the future and generate predictions with our autoregressive model. Note we use the `rows_update()` function to replace NAs with forecasted chlorophyll-a and updated initial condition values each day.
```{r}
for(i in 2:length(forecast_dates)){
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}

#Select current row of forecast_data to see if there is data to use for updating
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- forecast_data$chla[i] #Observed chl-a

#Update the initial condition
x_update <- EnKF(x_corr, y, ic_sd)
ic_distribution <- c(x_update[,1])

#Build temporary data frame
temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               ens = c(x_corr[,1],x_update[,1]),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

#Update rows
ens <- ens %>%
  rows_update(temp, by = c("date","ensemble_member","data_type"))
}
```

Plot output
```{r}
plot_many_forecasts(forecast_data, ens)
```

Assess forecast performance

Calculate mean prediction for each day
```{r}
forecast_means <- ens %>%
  filter(data_type == "fc") %>%
  group_by(date) %>%
  summarize(forecast_mean = mean(ens, na.rm = TRUE))

chla_observations <- lake_data %>%
  filter(datetime %in% forecast_dates)
```

Calculate bias and RMSE
```{r}
bias <- mean(forecast_means$forecast_mean - chla_observations$chla, na.rm = TRUE) 
bias

rmse <- round(sqrt(mean((forecast_means$forecast_mean - chla_observations$chla)^2, na.rm = TRUE)), 2)
rmse
```

## 8. Made management decisions using forecasts generated with different frequencies of data assimilation.

scenario data: do we close the beach on Sept 4?
```{r}
forecast_start_date <- "2018-10-04"

days_to_forecast = 7

forecast_dates <- seq.Date(from = as.Date(forecast_start_date), to = as.Date(forecast_start_date) + days_to_forecast, by = 'days')
```

make a forecast with last observation for data assimilation six days ago
set chla assimilation frequency
```{r}
chla_assimilation_frequency <- 8
```

```{r}
  chla_assimilation_dates <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(chla = ifelse(datetime %in% chla_assimilation_dates,chla,NA)) 
  
  curr_chla <- forecast_data$chla[1]
```

create data frames to hold initial conditions and forecasts
```{r}
ens <- tibble(date = rep(forecast_dates, each = n_members*2),
              ens = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Add OG initial conditions distribution to data frame
```{r}
ic_sd = 0.3
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              ens = ic_distribution,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))
ens <- ens %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```


for-loop for forecasting
Run forecast. Here, we loop through days into the future and generate predictions with our autoregressive model. Note we use the `rows_update()` function to replace NAs with forecasted chlorophyll-a and updated initial condition values each day.
```{r}
for(i in 2:length(forecast_dates)){
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}

#Select current row of forecast_data to see if there is data to use for updating
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- forecast_data$chla[i] #Observed chl-a

#Update the initial condition
x_update <- EnKF(x_corr, y, ic_sd)
ic_distribution <- c(x_update[,1])

#Build temporary data frame
temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               ens = c(x_corr[,1],x_update[,1]),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

#Update rows
ens <- ens %>%
  rows_update(temp, by = c("date","ensemble_member","data_type"))
}
fc1 <- ens
```

Plot output
```{r}
plot_scenario_forecasts(forecast_data, fc1)
```

And now with daily DA
make a forecast with last observation for data assimilation one day ago
set chla assimilation frequency
```{r}
chla_assimilation_frequency <- 1
```

```{r}
  chla_assimilation_dates <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(chla = ifelse(datetime %in% chla_assimilation_dates,chla,NA)) 
  
  curr_chla <- forecast_data$chla[1]
```

create data frames to hold initial conditions and forecasts
```{r}
ens <- tibble(date = rep(forecast_dates, each = n_members*2),
              ens = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Add OG initial conditions distribution to data frame
```{r}
ic_sd = 0.3
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              ens = ic_distribution,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))
ens <- ens %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```


for-loop for forecasting
Run forecast. Here, we loop through days into the future and generate predictions with our autoregressive model. Note we use the `rows_update()` function to replace NAs with forecasted chlorophyll-a and updated initial condition values each day.
```{r}
for(i in 2:length(forecast_dates)){
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}

#Select current row of forecast_data to see if there is data to use for updating
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- forecast_data$chla[i] #Observed chl-a

#Update the initial condition
x_update <- EnKF(x_corr, y, ic_sd)
ic_distribution <- c(x_update[,1])

#Build temporary data frame
temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               ens = c(x_corr[,1],x_update[,1]),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

#Update rows
ens <- ens %>%
  rows_update(temp, by = c("date","ensemble_member","data_type"))
}
fc2 <- ens
```

Plot output
```{r}
plot_scenario_forecasts(forecast_data, fc2)
```

A lot of question here for students to answer about why the forecasts look the way they do (the EnKF can't correct all the way to the observation!)

The big reveal
```{r}
plot_scenario_forecasts(forecast_data, fc1, show_final_obs = TRUE)
plot_scenario_forecasts(forecast_data, fc2, show_final_obs = TRUE)

```

Assess the forecasts - I bet the second set of forecasts has better RMSE, but you still got the wrong answer!

Assess forecast performance

For the low-frequency DA
```{r}
chla_observations <- lake_data %>%
  filter(datetime %in% forecast_dates)

forecast_means1 <- fc1 %>%
  filter(data_type == "fc") %>%
  group_by(date) %>%
  summarize(forecast_mean = mean(ens, na.rm = TRUE))

bias1 <- mean(forecast_means1$forecast_mean - chla_observations$chla, na.rm = TRUE) 
bias1

rmse1 <- round(sqrt(mean((forecast_means1$forecast_mean - chla_observations$chla)^2, na.rm = TRUE)), 2)
rmse1


```

For the high-frequency DA
```{r}
forecast_means2 <- fc2 %>%
  filter(data_type == "fc") %>%
  group_by(date) %>%
  summarize(forecast_mean = mean(ens, na.rm = TRUE))

bias2 <- mean(forecast_means2$forecast_mean - chla_observations$chla, na.rm = TRUE) 
bias2

rmse2 <- round(sqrt(mean((forecast_means2$forecast_mean - chla_observations$chla)^2, na.rm = TRUE)), 2)
rmse2
```


What are the other limitations in this forecasting system? What could be done to fix them?

## 9. Explore data assimilation for a different water quality variable.

Choose between temp, DO, and surface nitrogen. Alter the code below to read in the appropriate dataset:
1. water temperature: BARC_wtemp_celsius.csv
2. dissolved oxygen: BARC_dissolvedOxygen_milligramsPerLiter.csv
3. surface nitrogen: BARC_surfN_micromolesPerLiter.csv
```{r}
lake_data <- read_csv("./data/neon/BARC_chla_microgramsPerLiter.csv", show_col_types = FALSE) %>%
  rename(datetime = Date, chla = V1) %>%
  filter(cumsum(!is.na(chla)) > 0) %>%
  mutate(chla = ifelse(chla < 0, 0, chla))

head(lake_data)
```

Alter the code below to plot your new water quality variable rather than chl-a
```{r}
ggplot(data = lake_data, aes(x = datetime, y = chla))+
    geom_line(aes(color = "Chl-a"))+
    xlab("")+
    ylab(expression(paste("Chlorophyll-a (ug/L)")))+
    scale_color_manual(values = c("Chl-a" = "chartreuse4"), name = "")+
    theme_bw()
```

Fit an autoregressive model to your data. Alter the code below to fit a model to your new water quality variable.
```{r}
forecast_start_date <- "2020-09-25"

autocorrelation_data <- lake_data %>%
    filter(datetime < forecast_start_date) %>%
    mutate(chla = na.approx(chla, na.rm = F)) %>% 
    mutate(chla_lag = lag(chla)) %>% #EDIT THIS TO BE YOUR CHOSEN VARIABLE
    filter(complete.cases(.))

head(autocorrelation_data)

ar_model <- ar.ols(model_data$chla, order.max = 1, aic = FALSE,
                     intercept = TRUE, demean = TRUE)
```

Next, let's extract our model parameters and have a look at them.

First, $\beta_0$, the intercept:
```{r}
intercept = c(ar_model$x.intercept)
intercept
```

Next, $\beta_1$, the 1-day lag coefficient:
```{r}
ar1 = c(ar_model$ar)
ar1
```

Then, the mean of your chosen water quality variable:
```{r}
var_mean = c(ar_model$x.mean)
var_mean
```

Assess how well model fits data - make dataframe
```{r}
model_fit_plot_data <- tibble(date = model_data$datetime,
                              chla = model_data$chla, #EDIT THIS TO BE YOUR VARIABLE
                              model = mod)
```

Now, we can assess our model visually. We will plot the model predictions and observations.
```{r}
plot_mod_predictions(model_fit_plot_data, variable_name = "YOUR VARIABLE NAME HERE")
```

Calculate RMSE
```{r}
rmse <- round(sqrt(mean((mod - model_data$chla)^2, na.rm = TRUE)), 2)
rmse
```

Save residuals for process uncertainty
```{r}
residuals <- mod - model_data$chla
```

Calculate IC and process uncertainty

Set number of ensemble members
```{r}
n_members = 500
```

Read in high-frequency data
```{r}
high_frequency_data <- read_csv("./data/BARC_chla_microgramsPerLiter_highFrequency.csv", show_col_types = FALSE) %>%
  mutate(date = date(datetime),
         time = hms::as_hms(datetime)) %>%
  filter(date >= "2019-10-09" & date <= "2019-10-12")
```

Plot high-frequency data
```{r}
ggplot(data = high_frequency_data)+
  geom_line(aes(x = time, y = chla, group = date, color = as.factor(date)))+
  theme_bw()+
  labs(color = "Date")+
  xlab("Hour of day")+
  ylab("Chlorophyll-a (ug/L)")
```

Calculate standard deviation of variable each day
```{r}
ic_sd_dataframe <- high_frequency_data %>%
  group_by(date) %>%
  summarize(daily_sd_chla = sd(chla, na.rm = TRUE))
  
ic_sd <- mean(ic_sd_dataframe$daily_sd_chla, na.rm = TRUE)
ic_sd
```


Now, we can generate a distribution of initial conditions for our forecast using the current chlorophyll-a (`curr_chla`) and a standard deviation in units of ug/L calculated from high-frequency data from Lake Barco (`ic_sd`).

To do this, we will use the `rnorm()` function, which takes `n` draws from a normal distribution with a `mean` and `sd` specified as arguments to the function.
```{r}
curr_chla <- lake_data %>%
  filter(datetime == forecast_start_date) %>%
  pull(chla)

ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
```

Plot the distribution around your initial condition. This represents the **initial conditions uncertainty** of your forecast.
```{r}
plot_ic_dist(curr_chla, ic_distribution)
```

To calculate process uncertainty, we will define the standard deviation of the process uncertainty distribution, `sigma` as the standard deviation of the residuals. This is the uncertainty left over after we found the best parameters for fitting the model.

```{r}
sigma <- sd(residuals, na.rm = TRUE) # Process Uncertainty Noise Std Dev.; this is your sigma
```

Use `rnorm()` your process uncertainty distribution, using 0 as the mean and `sigma` as the standard deviation.
```{r}
process_distribution <- rnorm(n = n_members, mean = 0, sd = sigma)
```

Plot the process uncertainty distribution. We will use this distribution to account for uncertainty in our forecast.
```{r}
plot_process_dist(process_distribution)
```

Run forecasts with different frequencies of data assimilation and assess forecast performance: the goal is to figure out the optimal frequency of data collection to minimize RMSE over the forecast period.

set chla assimilation frequency
```{r}
chla_assimilation_frequency <- 1
```

```{r}
  chla_assimilation_dates <- forecast_dates[seq(1, length(forecast_dates), chla_assimilation_frequency)]
  
  forecast_data <- lake_data %>%
    select(datetime, chla) %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% forecast_dates) %>%
    mutate(chla = ifelse(datetime %in% chla_assimilation_dates,chla,NA)) 
```

create data frames to hold initial conditions and forecasts
```{r}
ens <- tibble(date = rep(forecast_dates, each = n_members*2),
              ens = NA_real_,
              ensemble_member = rep(1:n_members, times = length(forecast_dates)*2),
              data_type = rep(c("fc","ic"), each = n_members, times = length(forecast_dates)))
```

Add OG initial conditions distribution to data frame
```{r}
ic_sd = 0.3
ic_distribution <- rnorm(n = n_members, mean = curr_chla, sd = ic_sd)
temp_ic <- tibble(date = rep(forecast_dates[1], each = n_members),
              ens = ic_distribution,
              ensemble_member = c(1:n_members),
              data_type = rep("ic", times = n_members))
ens <- ens %>%
  rows_update(temp_ic, by = c("date","ensemble_member","data_type"))
```


for-loop for forecasting
Run forecast. Here, we loop through days into the future and generate predictions with our autoregressive model. Note we use the `rows_update()` function to replace NAs with forecasted chlorophyll-a and updated initial condition values each day.
```{r}
for(i in 2:length(forecast_dates)){
#Build model predictions for each ensemble
x_corr <- matrix(NA, nrow = n_members, ncol = 1)

for(m in 1:n_members){
  x_corr[m, ] = intercept + ar1 * (ic_distribution[m] - chla_mean) + chla_mean + process_distribution[m] 
}

#Select current row of forecast_data to see if there is data to use for updating
y <- matrix(NA, ncol= 1, nrow = 1)
y[1] <- forecast_data$chla[i] #Observed chl-a

#Update the initial condition
x_update <- EnKF(x_corr, y, ic_sd)
ic_distribution <- c(x_update[,1])

#Build temporary data frame
temp <- tibble(date = rep(forecast_dates[i], times = n_members*2),
               ens = c(x_corr[,1],x_update[,1]),
               ensemble_member = rep(1:n_members, times = 2),
               data_type = rep(c("fc","ic"), each = n_members))

#Update rows
ens <- ens %>%
  rows_update(temp, by = c("date","ensemble_member","data_type"))
}
```

Plot output
```{r}
plot_many_forecasts(forecast_data, ens)
```

Questions to assess which frequency of data assimilation is best for this variable and maybe compare that to chl-a results.